{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 598 DLH - Team 30 Final Project Report\n",
        "**Name(s):** Kudzai Bishi\n",
        "\n",
        "**Email(s):** kbishi2@illinois.edu\n",
        "\n",
        "**Project GitHub Repo:** https://github.com/598team30/DL4H_Team_30\n",
        "\n",
        "**Project Google Drive:** https://drive.google.com/drive/folders/1IfqKghs9ztuYZfVYV_mHXAvdZ6q-J2JU (contains video and word embeddings)\n",
        "\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "**Citation to the original paper:**\n",
        "Bardak, B., & Tan, M. (2021). Improving clinical outcome predictions using convolution over medical entities with multimodal learning. Artificial intelligence in medicine, 117, 102112. https://doi.org/10.1016/j.artmed.2021.102112\n",
        "\n",
        "**Original papers GitHub link:** https://github.com/tanlab/ConvolutionMedicalNer\n",
        "\n"
      ],
      "metadata": {
        "id": "j01aH0PR4Sg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "### Background of the problem\n",
        "\n",
        "Accurately predicting mortality and length of stay can help manage hospital resources, improve patient care, and save lives. After the release of the MIMIC-III (Medical Information Mart for Intensive Care) [1] EHR database, many studies utilized deep learning models on this database to predict different clinical outcomes. However, most studies mainly focused on using structured EHR data like diagnosis codes, vital signs, and lab results rather than unstructured clinical notes. This is because clinical notes are difficult to process due to being high dimensional and noisy. Although clinical notes present challenges, they are very detailed, containing various information about patients and their health status. This information could enhance vital healthcare predictions.\n",
        "\n",
        "The paper addresses this need to improve clinical outcomes by tackling the following types of problems: multimodal mortality (in-hospital and in-ICU) and in-ICU length of stay (>3 and >7 days) prediction (including data processing, feature engineering, and data integration). The author’s main goal was to find effective ways to integrate time series and clinical notes.\n",
        "\n",
        "### Paper explanation\n",
        "\n",
        "The paper proposes a novel convolutional-based multimodal deep learning architecture that uses time series and medical entity features to improve mortality (in-hospital and in-ICU) and in-ICU length of stay (>3 and >7 days) predictions. Key features of the proposed approach include:\n",
        "-\tExtracting time-series variables using ICU vital signals and lab results from MIMIC-Extract [2], an open-source data extraction pipeline,\n",
        "-\tExtracting medical entities from MIMIC-III clinical notes using med7 [3], a pre-trained clinical Named Entity Recognition (NER) model,\n",
        "-\tExploring different word embeddings on the medical entities, namely pre-trained Word2Vec, FastText, and a concatenation of both,\n",
        "-\tUtilizing a 3-layer 1D Convolutional Neural Network (CNN), with a max pooling layer to extract features from the medical entities and a single layer Gated Recurrent Unit (GRU) to extract features from the time series data,\n",
        "-\tLastly, combining the time series and medical entity features and then feeding them into a fully connected layer to produce the predictions.\n",
        "\n",
        "\n",
        "![Proposed Model Architecture](https://ars.els-cdn.com/content/image/1-s2.0-S0933365721001056-gr2_lrg.jpg)\n",
        "\n",
        "\n",
        "> Fig. 1. Overview of Proposed multimodal architecture for predicting mortality and length of stay.  \n",
        "\n",
        "The proposed method outperformed both a unimodal baseline model based on time series data alone and a multimodal baseline using averaged word embeddings (no CNN) on all prediction AUROC, AUPRC and F1 scores except for F1 score for length of stay > 7 days.\n",
        "\n",
        "This paper is important to the problem as it presents a  way to improve clinical outcome prediction accuracy by addressing challenges in data processing, feature engineering, and data integration.\n",
        "\n"
      ],
      "metadata": {
        "id": "AuPIRzP_TScB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scope of Reproducibility\n",
        "\n",
        "Hypotheses to be tested and the corresponding experiments to be run.\n",
        "\n",
        "**Hypothesis:** A multimodal deep learning approach of combining embedded medical entity features from a CNN and time series features from a GRU, trained using MIMIC-III data, will outperform both a unimodal approach of solely using the time series GRU and a multimodal approach without convolution on predicting mortality and length-of-stay.\n",
        "\n",
        "**Experiments:**\n",
        "1. Implement the proposed model (training, evaluation and testing).\n",
        ":\n",
        "**Ablations:**\n",
        "1. Model trained without convolution on medical entities (asses the effect of the convolution layer)\n",
        "2. Model trained without time series and model trained without medical entities (assess the effect of multimodal approach)\n",
        "\n",
        "**Additional Experiment:**\n",
        "1. Hyperparameter Tuning."
      ],
      "metadata": {
        "id": "uygL9tTPSVHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set Path/Mount Notebook to Google Drive\n",
        "\n",
        "This will mount to drive if using Google Colab.\n",
        "\n",
        "Note: running this will produce a popup that requires manual selections/authorization to proceed."
      ],
      "metadata": {
        "id": "dlv6knX04FiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive') # this is apparently sensitive to double or single quotes\n",
        "    PROJECT_PATH = \"/content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/\"\n",
        "else:\n",
        "    PROJECT_PATH = \"\"\n",
        "\n",
        "REQUIREMENTS_FILE = f\"{PROJECT_PATH}requirements.txt\""
      ],
      "metadata": {
        "id": "sfk8Zrul_E8V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5b24b670-4c12-4735-e716-c6ccd1357a4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "\n",
        "This section consists of runnable code with necessary annotations to show the executed experiment for testing the hypotheses. Includes the main sections **Environment**, **Data** and **Model** and corresponding subsections."
      ],
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment"
      ],
      "metadata": {
        "id": "LeGFkwSZGfVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python version\n",
        "\n",
        "Python Version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]"
      ],
      "metadata": {
        "id": "o5qxXC-tJ-pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Python Version:\", sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "X8KogIKAIF5r",
        "outputId": "defaa32d-e615-493d-9456-b0833b977b66"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Install packages"
      ],
      "metadata": {
        "id": "watl5mBuBEyx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r \"{REQUIREMENTS_FILE}\""
      ],
      "metadata": {
        "id": "mvRRNbpJDaP-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "546de093-ab86-4870-88d9-970828b4fe83"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-med7-lg==any (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading https://huggingface.co/kormilitzin/en_core_med7_lg/resolve/main/en_core_med7_lg-any-py3-none-any.whl (607.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.4/607.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gensim==4.3.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 1)) (4.3.2)\n",
            "Requirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 2)) (2.15.0)\n",
            "Collecting mittens==0.2 (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 3))\n",
            "  Downloading mittens-0.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 4)) (3.8.1)\n",
            "Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 5)) (1.25.2)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 6)) (2.0.3)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: scikit_learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 8)) (1.2.2)\n",
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.15.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.2->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 1)) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim==4.3.2->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 1)) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 4)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 4)) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 6)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 6)) (2024.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn==1.2.2->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (4.11.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.15.0)\n",
            "Collecting spacy<3.5.0,>=3.4.2 (from en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.0.9)\n",
            "Collecting thinc<8.2.0,>=8.1.0 (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1 (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2.0.10)\n",
            "Collecting typer<0.8.0,>=0.3.0 (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Collecting pathy>=0.3.5 (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading pathy-0.11.0-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2.31.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading pydantic-1.10.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.1.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (3.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (1.2.0)\n",
            "Collecting pathlib-abc==0.1.1 (from pathy>=0.3.5->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10))\n",
            "  Downloading pathlib_abc-0.1.1-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (0.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.5.0,>=3.4.2->en-core-med7-lg==any->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 10)) (1.1.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0->-r /content/gdrive/My Drive/Colab Notebooks/DL4H Team 30 Project/requirements.txt (line 9)) (3.2.2)\n",
            "Installing collected packages: wasabi, typer, pydantic, pathlib-abc, mittens, pathy, thinc, spacy, en-core-med7-lg\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.7.1\n",
            "    Uninstalling pydantic-2.7.1:\n",
            "      Successfully uninstalled pydantic-2.7.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.2.3\n",
            "    Uninstalling thinc-8.2.3:\n",
            "      Successfully uninstalled thinc-8.2.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.7.4\n",
            "    Uninstalling spacy-3.7.4:\n",
            "      Successfully uninstalled spacy-3.7.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.4.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed en-core-med7-lg-3.4.2.1 mittens-0.2 pathlib-abc-0.1.1 pathy-0.11.0 pydantic-1.10.15 spacy-3.4.4 thinc-8.1.12 typer-0.7.0 wasabi-0.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Import packages"
      ],
      "metadata": {
        "id": "wqnYP0HeBB_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages needed\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import re\n",
        "from statistics import mean\n",
        "from gensim.models import Word2Vec, FastText\n",
        "from mittens import GloVe\n",
        "import collections\n",
        "import nltk\n",
        "import spacy\n",
        "import time\n",
        "import random\n",
        "import gc\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Flatten, Dense, Dropout, Input, concatenate, Activation, Concatenate\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D\n",
        "from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D\n",
        "\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "from tensorflow.keras.regularizers import L2\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use only the first 24 hour of patient data after ICU admission\n",
        "window_size = 24\n",
        "# only consider patients with at least 30 hours of present data\n",
        "min_present_data = 30\n",
        "# set subsample data size\n",
        "sample_size = 100 # number of patients. Can put None to use full data, this will require 3+ days and ~ 24GB RAM\n",
        "\n",
        "# set seed\n",
        "SEED = 10\n",
        "np.random.seed(SEED)\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"Set seed\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_seed(SEED)\n",
        "\n",
        "# Define data path\n",
        "DATA_PATH = f\"{PROJECT_PATH}data\"\n",
        "EMBEDDING_PATH = f\"{PROJECT_PATH}embeddings\"\n",
        "RESULTS_PATH = f\"{PROJECT_PATH}results\""
      ],
      "metadata": {
        "id": "5jEoVHNDIxAp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start measuring runtime (not considering package installation)\n",
        "_START_RUNTIME = time.time()"
      ],
      "metadata": {
        "id": "tP9ie31OGkOp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Data\n",
        "This section includes raw data access instructions (MIMIC-Extract and MIMIC-III tables), descriptive statistics and data processing."
      ],
      "metadata": {
        "id": "ysQVBm2cIrKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data access and download instructions\n",
        "Can also find download instrcutions here: [GitHub README.md](https://github.com/598team30/DL4H_Team_30/blob/main/README.md#datasets ).\n",
        "\n",
        "####  MIMIC-III\n",
        "MIMIC-III ('Medical Information Mart for Intensive Care') [1] is a large, publically available database containing de-identified health-related data associated with over 45,000 patients who stayed in the Beth Israel Deaconess Medical Center ICU between 2001 and 2012. (see exact  statistics printed under section \"MIMIC-III clinical notes\")\n",
        "\n",
        "**To obtain access to the dataset:**\n",
        "\n",
        "1. Navigate to the MIMIC-III [1] PhysioNet page: https://physionet.org/content/mimiciii/1.4/\n",
        "2. Navigate to the `Files` section at the bottom of the page.\n",
        "3. Follow the instructions provided.\n",
        "4. After getting access, repeat steps 1 and 2. All files should now be accessible for download.\n",
        "5. Download `ADMISSIONS.csv.gz`, `ICUSTAYS.csv.gz` and `NOTEEVENTS.csv.gz`.\n",
        "6. Unzip each file.\n",
        "\n",
        "`ADMISSIONS.csv`, `ICUSTAYS.csv` and `NOTEEVENTS.csv` are the hospital admission data, ICU admission data and ICU clinical note data, respectively.\n",
        "\n",
        "####  MIMIC-Extract\n",
        "MIMIC-Extract [2] is an open-source data extraction and preprocessing pipeline that transforms raw MIMIC-III EHR data into datasets suitable for time-series prediction tasks. It includes patient ICU stays with the following criteria: the patient is at least 15 at the time of admission, the stay is the first known ICU admission for that patient, and the length of stay is between 12 hours and 10 days. The pipeline produces a cohort of 34,472 patients and 104 clinically aggregated time-series variables. (see printed statistics under section \"MIMIC-Extract time series data\")\n",
        "\n",
        "**To obtain access to the dataset:**\n",
        "\n",
        "Access and download the pre-processed output from Google Cloud Platform.\n",
        "1. Get access to MIMIC-III as outlined above\n",
        "2. Link your email account to your PhysioNet profile https://mimic.mit.edu/docs/gettingstarted/cloud/link/.\n",
        "2. Request access to the cloud resource for MIMIC-III as outlined in this link: https://mimic.mit.edu/docs/gettingstarted/cloud/request/.\n",
        "3. Click the access link to the Google Cloud Platform storage bucket sent via email.\n",
        "4. Navigate to the GitHub page MIMIC-Extract [2] https://github.com/MLforHealth/MIMIC_Extract.\n",
        "5. Navigate to the “Pre-processed Output” section and clicked the link provided for Google Cloud Platform (referred to as gcp).\n",
        "6. Download the data `all_hourly_data.zip`.\n",
        "7. Unzip each file\n",
        "\n",
        "`all_hourly_data.csv` contains the processed time series data.\n",
        "\n",
        "### Useful data definitions\n",
        "\n",
        "Reference: https://mimic.mit.edu/docs/iii/\n",
        "\n",
        "**Columns:**\n",
        "- SUBJECT_ID: identifies a unique patient\n",
        "- HADM_ID: identifies a unique admission to the hospital\n",
        "- ICUSTAY_ID: identifies a unique admission to the ICU\n",
        "- INTIME: time when the patient entered the ICU\n",
        "- OUTTIME: time when the patient left the ICU\n",
        "- CHARTTIME: time when measurements were documented/charted (can be a proxy for when the measurement was taken)\n"
      ],
      "metadata": {
        "id": "Jkbofr2Rdm57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIMIC-Extract time series data\n",
        "\n",
        "* Note this data took a while to load to colab (I did this very early on before the midterm)"
      ],
      "metadata": {
        "id": "xjcHi7HAB84V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "# dir and function to load raw data\n",
        "raw_mimic_extract_data_dir = f\"{DATA_PATH}/all_hourly_data.h5\"\n",
        "\n",
        "def load_raw_mimic_extract_data(raw_data_dir):\n",
        "    # load vital labs (ICU level data)\n",
        "    admissions = pd.read_hdf(raw_data_dir, 'vitals_labs')\n",
        "    #print('vital labs done')\n",
        "    # load patient level data\n",
        "    patients = pd.read_hdf(raw_data_dir, 'patients')\n",
        "    return admissions, patients\n",
        "\n",
        "# calculate statistics\n",
        "def calculate_stats(raw_admissions_data, raw_patients_data):\n",
        "    # implement this function to calculate the statistics\n",
        "    print(\" Statistics of MIMIC-Extract raw data:\")\n",
        "    print(\"   - \", \"Size/shape of dataset:\", raw_admissions_data.shape)\n",
        "    # below match statistics in paper\n",
        "    print(\"   - \",\"Total # of patients:\", len(raw_admissions_data.groupby('subject_id')))\n",
        "    print(\"   - \",\"Total # of hospital admissions:\", len(raw_admissions_data.index.get_level_values('hadm_id').unique()))\n",
        "    print(\"   - \",\"Total # of ICU admissions:\", len(raw_admissions_data.index.get_level_values('icustay_id').unique()))\n",
        "    print(\"   - \",\"Total # clinically aggregated time-series variables:\", len(raw_admissions_data.columns.levels[0].unique()))\n",
        "    # ['mort_hosp', 'mort_icu', 'los_icu']\n",
        "    print (\"   - In-hospital mortality distribution:\",\n",
        "           round(sum(raw_patients_data.mort_hosp.values)*100 / len(raw_patients_data.mort_hosp.values),1),\"%\")\n",
        "    print (\"   - In-ICU mortality distribution:\",\n",
        "           round(sum(raw_patients_data.mort_icu.values)*100 / len(raw_patients_data.mort_icu.values),1),\"%\")\n",
        "    print (\"   - Length-of-stay > 3 distribution:\",\n",
        "           round(sum(raw_patients_data['los_icu'] > 3)*100 / len(raw_patients_data.los_icu.values),1),\"%\")\n",
        "    print (\"   - Length-of-stay > 7 distribution:\",\n",
        "           round(sum(raw_patients_data['los_icu'] > 7)*100 / len(raw_patients_data.los_icu.values),1),\"%\")\n",
        "    print( \"NOTE: the above 4 distributions do not all match the final cohort distribution.\")\n",
        "\n",
        "# process raw data\n",
        "def simple_imputer(df):\n",
        "    \"\"\"\n",
        "    Impute missing values (not mentioned in the paper, but it is part of the code GitHub repo which\n",
        "    looks to be sourced from scripts on the MIMIC-Extract GitHub page).\n",
        "    \"\"\"\n",
        "    id_columns = ['subject_id', 'hadm_id', 'icustay_id']\n",
        "    idx = pd.IndexSlice\n",
        "    df = df.copy()\n",
        "    # drop the first 2 levels\n",
        "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
        "    # fill missing ICU means, first with forward fill, then group averages, then filling the remaining with 0\n",
        "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
        "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(id_columns).mean()\n",
        "\n",
        "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(id_columns).fillna(\n",
        "        method='ffill'\n",
        "    ).groupby(id_columns).fillna(icustay_means).fillna(0)\n",
        "\n",
        "    # create a mask column as an indicator for when the count is greater than 0\n",
        "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
        "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
        "    # ??\n",
        "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
        "    hours_of_absence = is_absent.cumsum() #cumulative sum\n",
        "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
        "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
        "\n",
        "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
        "    # fill in missing time since measured with 100\n",
        "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
        "\n",
        "    # sort the dataframe by column names\n",
        "    df_out.sort_index(axis=1, inplace=True)\n",
        "    return df_out\n",
        "\n",
        "def process_time_series_data(admissions, patients):\n",
        "    \"\"\"\n",
        "    Take a sample of the datasets and process as described in paper:\n",
        "        1. Subsample the data\n",
        "        2. Only consider the patients with at least 30 h of present data\n",
        "        3. Create boolean lables for length of stay >3 and >7 targets\n",
        "        4. Use the first 24 h of patient’s data after ICU admission with at least 30 h of present data\n",
        "        5. Split data into train/validation/test with 70%/10%/20% ratio\n",
        "        6. Impute the admissions data as provided in MIMIC-Extract GitHub code (not described in the paper, but used in code)\n",
        "\n",
        "    Arguments:\n",
        "        admissions: raw admissions data\n",
        "        patients: raw patient data\n",
        "\n",
        "    Outputs: processed sample patient dataset, and split admissions and patient datasets\n",
        "\n",
        "    Note: using a function instead of running these steps outside the function changes the full dataset memory requirements from 13GB RAM\n",
        "    to 30GB RAM.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Subsample the data\n",
        "    # subsampling to retain only data for the first n (sample size) unique subjects ids (patients) for demo purposes\n",
        "    subsample_subject_id = admissions.index.get_level_values('subject_id').unique()[:sample_size]\n",
        "    admissions = admissions[admissions.index.get_level_values('subject_id').isin(subsample_subject_id)]\n",
        "    patients = patients[patients.index.get_level_values('subject_id').isin(subsample_subject_id)]\n",
        "    # should produce 6682 rows vs 2200954\n",
        "    print(\"\\n Size/shape of sample admissions data: \", admissions.shape)\n",
        "\n",
        "    # only consider patients with at least 30 hours of present data\n",
        "    patients = patients[patients.max_hours > min_present_data][['mort_hosp', 'mort_icu', 'los_icu']]\n",
        "    # create boolean labels for length of stay >3 and >7 targets\n",
        "    patients['los_3'] = patients['los_icu'] > 3\n",
        "    patients['los_7'] = patients['los_icu'] > 7\n",
        "    # drop the original length of stay column\n",
        "    patients.drop(columns=['los_icu'], inplace=True)\n",
        "    patients.astype(float)\n",
        "\n",
        "    # drop any ICU admissions that were removed from the patient data and where the hours in ICU are less than the window size\n",
        "    # Overall this means only using the first 24 h of patient’s data after ICU admission for patients\n",
        "    # with at least 30 hours of present data (as described in section 3.1. Data in the paper)\n",
        "    admissions = admissions[\n",
        "        (admissions.index.get_level_values('icustay_id').isin(set(patients.index.get_level_values('icustay_id')))) &\n",
        "        (admissions.index.get_level_values('hours_in') < window_size)]\n",
        "\n",
        "    # split dataset based on patients into 70% training, 10% validation and 20% testing sets\n",
        "    train_split, val_split, test_split = 0.7, 0.1, 0.2\n",
        "\n",
        "    ## make sure the 2 datasets have the same patients\n",
        "    admissions_subj_idx,  patients_subj_idx = [df.index.get_level_values('subject_id') for df in (admissions, patients)]\n",
        "    admissions_patients = set(admissions_subj_idx)\n",
        "    assert admissions_patients == set(patients_subj_idx), \"Subject ID pools differ!\" # is this necessary??\n",
        "\n",
        "    np.random.seed(SEED)\n",
        "    all_patients, N = np.random.permutation(list(admissions_patients)), len(admissions_patients)\n",
        "    N_train, N_val, N_test = int(train_split * N), int(val_split * N), int(test_split * N)\n",
        "    train_subj_ids = all_patients[:N_train]\n",
        "    val_subj_ids   = all_patients[N_train:N_train + N_val]\n",
        "    test_subj_ids  = all_patients[N_train+N_val:]\n",
        "\n",
        "    print(f\"  Training split : {round(len(train_subj_ids)/N*100,1)}%\")\n",
        "    print(f\"  Validation split : {round(len(val_subj_ids)/N*100,1)}%\")\n",
        "    print(f\"  Testing split :: {round(len(test_subj_ids)/N*100,1)}%\")\n",
        "\n",
        "    [(admissions_train, admissions_val, admissions_test), (patients_train, patients_val, patients_test)] = [\n",
        "        [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj_ids, val_subj_ids, test_subj_ids)] \\\n",
        "        for df in (admissions, patients)\n",
        "    ]\n",
        "\n",
        "    ### normalize the column means using the training dataset mean and standard deviation\n",
        "    idx = pd.IndexSlice\n",
        "    admissions_means_train = admissions_train.loc[:, idx[:,'mean']].mean(axis=0)\n",
        "    admissions_stds_train = admissions_train.loc[:, idx[:,'mean']].std(axis=0)\n",
        "\n",
        "    admissions_train.loc[:, idx[:,'mean']] = (admissions_train.loc[:, idx[:,'mean']] - admissions_means_train)/admissions_stds_train\n",
        "    admissions_val.loc[:, idx[:,'mean']] = (admissions_val.loc[:, idx[:,'mean']] - admissions_means_train)/admissions_stds_train\n",
        "    admissions_test.loc[:, idx[:,'mean']] = (admissions_test.loc[:, idx[:,'mean']] - admissions_means_train)/admissions_stds_train\n",
        "\n",
        "    # impute the admissions data\n",
        "    admissions_train, admissions_val, admissions_test = [\n",
        "        simple_imputer(df) for df in (admissions_train, admissions_val, admissions_test)\n",
        "    ]\n",
        "\n",
        "    # check that there are no more nulls\n",
        "    for df in admissions_train, admissions_val, admissions_test: assert not df.isnull().any().any()\n",
        "    for df in patients_train, patients_val, patients_test: assert not df.isnull().any().any()\n",
        "\n",
        "    # Split the patient data the same as admissions data (counts are more than reported, but the code seems ok)\n",
        "    [(patients_train, patients_val, patients_test)] = [\n",
        "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj_ids, val_subj_ids, test_subj_ids)] \\\n",
        "    for df in (patients,) ]\n",
        "\n",
        "    return admissions_train, admissions_val, admissions_test, patients, patients_train, patients_val, patients_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## implement functions\n",
        "\n",
        "# load full raw data\n",
        "raw_admissions, raw_patients = load_raw_mimic_extract_data(raw_mimic_extract_data_dir)\n",
        "# calculate and print statistics\n",
        "calculate_stats(raw_admissions,raw_patients)\n",
        "# process sample data\n",
        "admissions_train, admissions_val, admissions_test, patients, patients_train, patients_val, patients_test = process_time_series_data(raw_admissions, raw_patients)\n",
        "\n",
        "del raw_admissions\n",
        "del raw_patients\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tc_xLJ8PZCf",
        "outputId": "ee4593ab-cfbb-421d-e880-c7cb75318985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Statistics of MIMIC-Extract raw data:\n",
            "   -  Size/shape of dataset: (2200954, 312)\n",
            "   -  Total # of patients: 34472\n",
            "   -  Total # of hospital admissions: 34472\n",
            "   -  Total # of ICU admissions: 34472\n",
            "   -  Total # clinically aggregated time-series variables: 104\n",
            "   - In-hospital mortality distribution: 9.6 %\n",
            "   - In-ICU mortality distribution: 6.6 %\n",
            "   - Length-of-stay > 3 distribution: 29.9 %\n",
            "   - Length-of-stay > 7 distribution: 5.4 %\n",
            "NOTE: the above 4 distributions do not all match the final cohort distribution.\n",
            "\n",
            " Size/shape of sample admissions data:  (6682, 312)\n",
            "  Training split : 69.4%\n",
            "  Validation split : 9.7%\n",
            "  Testing split :: 20.8%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MIMIC-III clinical notes\n",
        "\n"
      ],
      "metadata": {
        "id": "MBNmXv1DCKpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dir and function to load raw clinical notes data\n",
        "\n",
        "raw_mimic_iii_noteevents_data_dir = f\"{DATA_PATH}/NOTEEVENTS.csv\"\n",
        "raw_mimic_iii_admissions_data_dir = f\"{DATA_PATH}/ADMISSIONS.csv\" # only for statistics\n",
        "raw_mimic_iii_icustays_data_dir = f\"{DATA_PATH}/ICUSTAYS.csv\" # only for statistics\n",
        "\n",
        "def load_raw_mimic_iii_notes_data():\n",
        "    # load ICU clinical note data\n",
        "    noteevents_data = pd.read_csv(raw_mimic_iii_noteevents_data_dir,low_memory=False)\n",
        "    # load hospital admission data (for statistics)\n",
        "    admission_data  = pd.read_csv(raw_mimic_iii_admissions_data_dir,low_memory=False)\n",
        "    # load ICU admission data (for statistics)\n",
        "    icustays_data  = pd.read_csv(raw_mimic_iii_icustays_data_dir,low_memory=False)\n",
        "    return noteevents_data , admission_data , icustays_data\n",
        "\n",
        "# calculate statistics\n",
        "def calculate_stats(admission_data,icustays_data,notes_data):\n",
        "    # implement this function to calculate the statistics\n",
        "    print(\"Statistics of MIMIC-III raw data:\")\n",
        "    print(\"   - \", \"Size/shape of hospital admissions dataset:\", admission_data.shape)\n",
        "    print(\"   - \", \"Size/shape of ICU admissions dataset:\", icustays_data.shape)\n",
        "    print(\"   - \",\"Total # of patients:\", len(admission_data['SUBJECT_ID'].unique()))\n",
        "    print(\"   - \",\"Total # of hospital admissions:\", len(admission_data['HADM_ID'].unique()))\n",
        "    print(\"   - \",\"Total # of ICU admissions:\", len(icustays_data['ICUSTAY_ID'].unique()))\n",
        "    print(\"   - \",\"Total # of in ICU patients:\", len(icustays_data['SUBJECT_ID'].unique())) # less patients than paper states = hospital patients??\n",
        "    print(\"   - \",\"Total # of in note categories:\", len(list(notes_data['CATEGORY'].unique())))\n",
        "\n",
        "\n",
        "# process raw data\n",
        "def process_data(raw_noteevents_data,patient_ids):\n",
        "    \"\"\"\n",
        "    Take a sample of the datasets and process as described in the paper:\n",
        "        1. drop discharge summaries\n",
        "        2. drop clinical notes without chart time information\n",
        "        3. subsample the data by subject ids from processed time series data\n",
        "        3. drop patients without any clinical notes in 24 h\n",
        "        4. Preprocess notes with author-provided script (preprocess.py)\n",
        "        5. Apply the clinical NER model to get medical entities\n",
        "        6. Apply Word2Vec, FastText, and a concatenation of both word\n",
        "            embeddings to the medical entities to create representations\n",
        "\n",
        "    Arguments:\n",
        "        raw_noteevents_data: raw clinical notes data\n",
        "        patient_ids: patient ids from the time series cohort\n",
        "\n",
        "    Outputs:\n",
        "        word2vec_embeddings: patient medical entity Word2Vec embeddings dictionary\n",
        "        fasttext_embeddings: patient medical entity FastText embeddings dictionary\n",
        "        concatenated_embeddings: Combined Word2Vec and FastText embeddings dictionary\n",
        "    \"\"\"\n",
        "    # drop discharge summaries\n",
        "    noteevents_data = raw_noteevents_data[~(raw_noteevents_data['CATEGORY'] == 'Discharge summary')]\n",
        "    # drop clinical notes without chart time information\n",
        "    noteevents_data.dropna(subset=['CHARTTIME'],inplace=True)\n",
        "    # subsample the data by subject ids from processed time series data\n",
        "    noteevents_data = noteevents_data[noteevents_data['SUBJECT_ID'].isin(patient_ids)]\n",
        "\n",
        "    # only keep patients with clinical notes within 24 h\n",
        "    ## first join to patient-level data to get intime attribute (time patient entered ICU)\n",
        "    patients = pd.read_hdf(raw_mimic_extract_data_dir, 'patients').reset_index()\n",
        "    patients.rename(columns = {\"subject_id\": \"SUBJECT_ID\", \"hadm_id\": \"HADM_ID\"}, inplace=True)\n",
        "    admission_notes_data = pd.merge(noteevents_data[['SUBJECT_ID','CHARTTIME', 'TEXT']],\n",
        "                            patients[['SUBJECT_ID','HADM_ID','intime']],\n",
        "                            on = ['SUBJECT_ID'],\n",
        "                            how = 'left')\n",
        "    admission_notes_data['CHARTTIME'] = pd.to_datetime(admission_notes_data['CHARTTIME'])\n",
        "    admission_notes_data = admission_notes_data[((admission_notes_data['CHARTTIME']-admission_notes_data['intime']).dt.total_seconds()/(60*60))<window_size]\n",
        "\n",
        "    del patients, noteevents_data\n",
        "\n",
        "    # preprocess note text with author provided script (preprocess.py)\n",
        "    preprocess_path = f\"{PROJECT_PATH}preprocess.py\"\n",
        "    %run \"{preprocess_path}\"\n",
        "    nltk.download('punkt')\n",
        "    admission_notes_data['preprocessed_text'] = admission_notes_data['TEXT'].apply(getSentences)\n",
        "\n",
        "    # apply med7 on the clinical note text (takes 2 full days on full data)\n",
        "    med7 = spacy.load(\"en_core_med7_lg\")\n",
        "    ## --\n",
        "    admission_notes_data['ner'] = None\n",
        "    count = 0\n",
        "    preprocessed_index = {}\n",
        "    for i in admission_notes_data.itertuples():\n",
        "\n",
        "        if count % 1000 == 0: # not very useful with small sample\n",
        "            print(\"MED 7 record: \",count)\n",
        "\n",
        "        ind = i.Index\n",
        "        text = i.preprocessed_text\n",
        "\n",
        "        all_pred = []\n",
        "        for each_sent in text:\n",
        "            try:\n",
        "                doc = med7(each_sent)\n",
        "                result = ([(ent.text, ent.label_) for ent in doc.ents])\n",
        "                if len(result) == 0: continue   ##\n",
        "                all_pred.append(result)\n",
        "            except:\n",
        "                print(\"error..\")\n",
        "                continue\n",
        "        admission_notes_data.at[ind, 'ner'] = all_pred\n",
        "        count += 1\n",
        "    ## remove rows without medical entities\n",
        "    admission_notes_data = admission_notes_data[admission_notes_data['ner'].str.len() != 0]\n",
        "\n",
        "    # change the admission notes data to a dictionary with patient ids as keys and note text as values (list items)\n",
        "    # to apply word embeddings\n",
        "    med7_ner_dict = {}\n",
        "\n",
        "    for ii in admission_notes_data.itertuples():\n",
        "        p_id = ii.SUBJECT_ID\n",
        "        ind = ii.Index\n",
        "        try:\n",
        "            new_ner = admission_notes_data.loc[ind].ner\n",
        "        except:\n",
        "            new_ner = []\n",
        "\n",
        "        unique = set()\n",
        "        new_temp = []\n",
        "        for j in new_ner:\n",
        "            for k in j:\n",
        "                unique.add(k[0])\n",
        "                new_temp.append(k)\n",
        "\n",
        "        if p_id in med7_ner_dict:\n",
        "            for i in new_temp:\n",
        "                med7_ner_dict[p_id].append(i)\n",
        "        else:\n",
        "            med7_ner_dict[p_id] = new_temp\n",
        "\n",
        "    del admission_notes_data\n",
        "\n",
        "    # Apply word embeddings\n",
        "    ## load word emdedding models\n",
        "    w2vec = Word2Vec.load(f\"{EMBEDDING_PATH}/word2vec.model\")\n",
        "    fasttext = FastText.load(f\"{EMBEDDING_PATH}/fasttext.model\")\n",
        "\n",
        "    ## define mean function\n",
        "    def mean(a):\n",
        "        return sum(a) / len(a)\n",
        "\n",
        "    for data in [med7_ner_dict]:\n",
        "        # processing fasttext and word2vec together as they have the same words\n",
        "        # this may have been different when the paper was published\n",
        "        print(\"w2vec and fasttext embeddings starting..\")\n",
        "        word2vec_embeddings = {}\n",
        "        fasttext_embeddings = {}\n",
        "        concatenated_embeddings = {}\n",
        "        for k,v in data.items():\n",
        "            patient_temp_w2v, patient_temp_ftv = [], []\n",
        "            for i in v:\n",
        "                try:\n",
        "                    patient_temp_w2v.append(w2vec.wv[i[0]])\n",
        "                    patient_temp_ftv.append(fasttext.wv[i[0]])\n",
        "                except:\n",
        "                    avg_w2v, avg_ftv = [],[]\n",
        "                    temp_w2v, temp_ftv= [], []\n",
        "                    num = 0\n",
        "                    # where there are multiple words, split the text, apply embedding to each word and take the average\n",
        "                    if len(i[0].split(\" \")) > 1:\n",
        "                        for each_word in i[0].split(\" \"):\n",
        "                            try:\n",
        "                                temp_w2v, temp_ftv = w2vec.wv[each_word], fasttext.wv[each_word]\n",
        "                                avg_w2v.append(temp_w2v)\n",
        "                                avg_ftv.append(temp_ftv)\n",
        "                                num += 1\n",
        "                            except:\n",
        "                                pass\n",
        "                        if num == 0: continue\n",
        "                        avg_w2v, avg_ftv = np.asarray(avg_w2v), np.asarray(avg_ftv)\n",
        "                        t = np.asarray(list(map(mean, zip(*avg_w2v))))\n",
        "                        patient_temp_w2v.append(t)\n",
        "                        t = np.asarray(list(map(mean, zip(*avg_ftv))))\n",
        "                        patient_temp_ftv.append(t)\n",
        "            if len(patient_temp_w2v) == 0: continue # checking w2v only\n",
        "            word2vec_embeddings[k] = patient_temp_w2v\n",
        "            fasttext_embeddings[k] = patient_temp_ftv\n",
        "\n",
        "        #############################################################################\n",
        "\n",
        "        print(\"combined emdeddings starting..\")\n",
        "        # concatenate the Word2Vec and FastText representations horizontally (ci ∈ ℝ200).\n",
        "        # add zero padding for missing word embeddings, authors only pad Word2vec, but fastext\n",
        "        # and word2vec have the same number of words currently, so padding both.\n",
        "        for k,v in data.items():\n",
        "            patient_temp_concat = []\n",
        "        #     if k != 6: continue\n",
        "            for i in v:\n",
        "                w2vec_temp, fasttext_temp = [], []\n",
        "                try:\n",
        "                    w2vec_temp, fasttext_temp = w2vec.wv[i[0]], fasttext.wv[i[0]]\n",
        "                except:\n",
        "                    avg_w2v, avg_ftv = [],[]\n",
        "                    temp_w2v, temp_ftv= [], []\n",
        "                    num = 0\n",
        "                    # where there are mutliple words, split the text, apply embedding to each word and take the average\n",
        "                    if len(i[0].split(\" \")) > 1:\n",
        "                        for each_word in i[0].split(\" \"):\n",
        "                            try:\n",
        "                                temp_w2v, temp_ftv = w2vec.wv[each_word], fasttext.wv[each_word]\n",
        "                                avg_w2v.append(temp_w2v)\n",
        "                                avg_ftv.append(temp_ftv)\n",
        "                                num += 1\n",
        "                            except:\n",
        "                                pass\n",
        "                        if num == 0:\n",
        "                            w2vec_temp, fasttext_temp = [0] * 100, [0] * 100\n",
        "                        else:\n",
        "                            avg_w2v, avg_ftv = np.asarray(avg_w2v), np.asarray(avg_ftv)\n",
        "                            w2vec_temp = np.asarray(list(map(mean, zip(*avg_w2v))))\n",
        "                            fasttext_temp = np.asarray(list(map(mean, zip(*avg_ftv))))\n",
        "                    else:\n",
        "                        w2vec_temp, fasttext_temp = [0] * 100, [0] * 100\n",
        "\n",
        "                appended = np.append(fasttext_temp, w2vec_temp, 0)\n",
        "                patient_temp_concat.append(appended)\n",
        "\n",
        "            if len(patient_temp_concat[0]) == 0: continue # if no embeddings, skip,\n",
        "            concatenated_embeddings[k] = patient_temp_concat\n",
        "\n",
        "        #print(len(word2vec_embeddings), len(fasttext_embeddings), len(concatenated_embeddings))\n",
        "\n",
        "    # only keep embeddings that are present in word2vec\n",
        "    diff = set(fasttext_embeddings.keys()).difference(set(word2vec_embeddings))\n",
        "    for i in diff:\n",
        "        del fasttext_embeddings[i]\n",
        "\n",
        "    diff = set(concatenated_embeddings.keys()).difference(set(word2vec_embeddings))\n",
        "    for i in diff:\n",
        "        del concatenated_embeddings[i]\n",
        "\n",
        "    print(\"word2vec patients: \",len(word2vec_embeddings))\n",
        "    print(\"fasttext patients: \",len(fasttext_embeddings))\n",
        "    print(\"combined patients: \",len(concatenated_embeddings))\n",
        "\n",
        "    return word2vec_embeddings, fasttext_embeddings, concatenated_embeddings\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wT5t9jlHB6TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## implement functions\n",
        "# Extract raw data and print statistics\n",
        "raw_noteevents_data, raw_admission_data, raw_icustays_data = load_raw_mimic_iii_notes_data()\n",
        "calculate_stats(raw_admission_data, raw_icustays_data,raw_noteevents_data)\n",
        "\n",
        "del raw_admission_data, raw_icustays_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpu6C8H7DHNZ",
        "outputId": "a2501683-cf82-49d8-9d13-8198215db737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics of MIMIC-III raw data:\n",
            "   -  Size/shape of hospital admissions dataset: (58976, 19)\n",
            "   -  Size/shape of ICU admissions dataset: (61532, 12)\n",
            "   -  Total # of patients: 46520\n",
            "   -  Total # of hospital admissions: 58976\n",
            "   -  Total # of ICU admissions: 61532\n",
            "   -  Total # of in ICU patients: 46476\n",
            "   -  Total # of in note categories: 15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## implement functions\n",
        "# store subject/patient ids from processed time series data\n",
        "subject_ids = list(patients.index.get_level_values('subject_id'))\n",
        "\n",
        "# process data\n",
        "word2vec_embeddings, fasttext_embeddings, concatenated_embeddings = process_data(raw_noteevents_data,subject_ids)\n",
        "\n",
        "del raw_noteevents_data\n",
        "del FastText, Word2Vec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJHrmZEfRZex",
        "outputId": "93a34aca-3dc2-48ff-cf20-80f209b9f856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MED 7 record:  0\n",
            "w2vec and fasttext embeddings starting..\n",
            "combined emdeddings starting..\n",
            "word2vec patients:  72\n",
            "fasttext patients:  72\n",
            "combined patients:  72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final time series datasets"
      ],
      "metadata": {
        "id": "mhJ2xzJxtpX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only keep time series patients with notes\n",
        "patients_to_keep = word2vec_embeddings.keys()\n",
        "\n",
        "train_patients = patients_train.index.get_level_values('subject_id').intersection(patients_to_keep)\n",
        "val_patients = patients_val.index.get_level_values('subject_id').intersection(patients_to_keep)\n",
        "test_patients = patients_test.index.get_level_values('subject_id').intersection(patients_to_keep)\n",
        "\n",
        "## target\n",
        "y_train = patients_train.loc[train_patients]\n",
        "y_val = patients_val.loc[val_patients]\n",
        "y_test = patients_test.loc[test_patients]\n",
        "\n",
        "## variables\n",
        "admissions_train = admissions_train.loc[train_patients]\n",
        "admissions_val = admissions_val.loc[val_patients]\n",
        "admissions_test = admissions_test.loc[test_patients]\n",
        "\n",
        "### only retain the hourly mean sub columns for each measurement column\n",
        "admissions_train = admissions_train.loc[:, pd.IndexSlice[:, 'mean']]\n",
        "admissions_val = admissions_val.loc[:, pd.IndexSlice[:, 'mean']]\n",
        "admissions_test = admissions_test.loc[:, pd.IndexSlice[:, 'mean']]\n",
        "\n",
        "### get the matrix representation of the admissions data\n",
        "x_train_ts = admissions_train.values\n",
        "x_val_ts = admissions_val.values\n",
        "x_test_ts = admissions_test.values\n",
        "\n",
        "del admissions_train, admissions_val, admissions_test\n",
        "gc.collect()\n",
        "\n",
        "### reshape the data for time series prediction\n",
        "x_train_ts = x_train_ts.reshape(int(x_train_ts.shape[0] / 24), 24, 104)\n",
        "x_val_ts = x_val_ts.reshape(int(x_val_ts.shape[0] / 24), 24, 104)\n",
        "x_test_ts = x_test_ts.reshape(int(x_test_ts.shape[0] / 24), 24, 104)"
      ],
      "metadata": {
        "id": "CAwmjmqN-SIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If full datasets were processed, save for experiments and ablations\n",
        "if sample_size == None:\n",
        "    pd.to_pickle(x_train_ts, f\"{DATA_PATH}/full_x_train.pkl\")\n",
        "    pd.to_pickle(x_val_ts, f\"{DATA_PATH}/full_x_val.pkl\")\n",
        "    pd.to_pickle(x_test_ts, f\"{DATA_PATH}/full_x_test.pkl\")\n",
        "\n",
        "    pd.to_pickle(y_train, f\"{DATA_PATH}/full_y_train.pkl\")\n",
        "    pd.to_pickle(y_val, f\"{DATA_PATH}/full_y_val.pkl\")\n",
        "    pd.to_pickle(y_test, f\"{DATA_PATH}/full_y_test.pkl\")\n",
        "\n",
        "    pd.to_pickle(train_patients, f\"{DATA_PATH}/full_train_ids.pkl\")\n",
        "    pd.to_pickle(val_patients, f\"{DATA_PATH}/full_dev_ids.pkl\")\n",
        "    pd.to_pickle(test_patients, f\"{DATA_PATH}/full_test_ids.pkl\")\n",
        "\n",
        "    pd.to_pickle(word2vec_embeddings, f\"{DATA_PATH}/full_word2vec_embeddings.pkl\")\n",
        "    pd.to_pickle(fasttext_embeddings, f\"{DATA_PATH}/full_fasttext_embeddings.pkl\")\n",
        "    pd.to_pickle(concatenated_embeddings, f\"{DATA_PATH}/full_concat_embeddings.pkl\")\n"
      ],
      "metadata": {
        "id": "WLHqfkdzd895"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##   Model\n",
        "The section includes the proposed model definition function, model training and evaluation of the subsampled processed data.\n",
        "\n",
        "-------------------------------\n",
        "\n",
        "**Citation to the original paper:**\n",
        "Bardak, B., & Tan, M. (2021). Improving clinical outcome predictions using convolution over medical entities with multimodal learning. Artificial intelligence in medicine, 117, 102112. https://doi.org/10.1016/j.artmed.2021.102112\n",
        "\n",
        "**Original papers GitHub link:** https://github.com/tanlab/ConvolutionMedicalNer\n",
        "\n",
        "---\n",
        "\n",
        "The proposed model is a convolutional-based multimodal deep learning architecture. This model is implemented using Keras.\n",
        "\n",
        "**Model architecture:** (layer number/size/type, activation function, etc)\n",
        "\n",
        "-\tA 3-layer 1D Convolutional Neural Network (CNN), with filter sizes 32, 64, and 96 respectively, Relu activation and a max pooling layer to extract features from the medical entities\n",
        "- A single-layer Gated Recurrent Unit (GRU) with\n",
        "256 hidden units to extract features from the time series data.\n",
        "-\tLastly one fully connected layer with 256 hidden units and Relu activation, that takes the concatenated outputs of above layers to make predictions.\n",
        "\n",
        "\n",
        "**Training objectives:** (loss function, optimizer, weight of each loss term, etc)\n",
        "\n",
        "- 0.2 dropout rate is used at the end of the fully connected layer\n",
        "- L2 norm for sparsity regularization is selected with A 0.01 scale factor.\n",
        "- ADAM algorithm with a learning rate of 0.001 is used for optimization.\n",
        "- All models are trained to minimize the binary cross-entropy loss.\n",
        "- Batch size of 64 is used for training. (not specified in paper, taken from code)\n",
        "\n",
        "**Evaluation metrics:**\n",
        "\n",
        "Three different metrics are used due to class imbalances; AUROC, AUPRC and F1.\n",
        "\n",
        "1. AUROC (area under the Receiver Operating Characteristic curve) is a commonly used metric that is robust to imbalanced data.\n",
        "2. AUPRC (area under the precision-recall curve) is similar to AUROC but does not consider true negatives. Since the data contains a lot of true negatives, this metric is a meaningful measure of success.\n",
        "3. F1 combines precision and recall while giving equal importance to false negatives and positives.\n",
        "\n",
        "For all three metrics, the higher the score, the better the model.\n",
        "\n",
        "Reference: https://link.springer.com/chapter/10.1007/978-3-030-82184-5_3#Sec10\n",
        "(see subsection 3.4.2.2 Real-Value Prediction for Classification)\n",
        "\n",
        "---\n",
        "\n",
        "**Computational requirements:** The full proposed model successfully runs in free Google Colab both under CPU and GPU (as initially predicted in the project proposal). The model trained using the full dataset runs for:\n",
        "- about 5-6 hours with 13 GB CPU RAM (each epoch running on average for 25 seconds) and,\n",
        "- about 1 hour 42 mins on 15GB GPU RAM (each epoch running on average for 7 seconds).\n",
        "\n",
        "The model is trained for 50 epochs for each embedding and prediction problem, with early stopping after 3 epochs with no change in validation loss (most iterations ran for between 5-7 epochs). Each model was trained 10 times with different initialization seeds.\n",
        "\n",
        "**NOTE:** the pretrained models (trained outside this notebook on the full dataset) are loaded and tested under results section.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GCnQ-owWFNgM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parameters"
      ],
      "metadata": {
        "id": "3RwF0zJ2q11E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
        "embedding_dict = [word2vec_embeddings, fasttext_embeddings, concatenated_embeddings]\n",
        "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "\n",
        "# parameters/inputs\n",
        "num_epoch = 3 # for demo (original in paper = 50)\n",
        "model_patience = 3\n",
        "monitor_criteria = 'val_loss'\n",
        "ner_representation_limit = 64 # size of patient input matrix\n",
        "\n",
        "## Hyperparameters\n",
        "batch_size = 64 # not specified in paper\n",
        "ts_hidden_unit = 256\n",
        "filter_sizes = [32,64,96]\n",
        "# the rest are specified directly in the model function.\n",
        "\n",
        "maxiter = 2 # 1 iteration for demo (original = 10)"
      ],
      "metadata": {
        "id": "zRSufpPCq0nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Proposed Model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C8WCFI08Vaxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "def proposed_model(number_of_unit, embedding_name, ner_limit, num_filter):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        number_of_unit: GRU number of hidden units\n",
        "        embedding_name: name of embedding\n",
        "        ner_limit: size of patient matrix\n",
        "        num_filter: list of 3 CNN filter sizes\n",
        "\n",
        "    Outputs:\n",
        "        model: the proposed multimodal model\n",
        "    \"\"\"\n",
        "    if embedding_name == \"concat\":\n",
        "        input_dimension = 200\n",
        "    else:\n",
        "        input_dimension = 100\n",
        "\n",
        "    # 24 hours and 104 time-series variable\n",
        "    ts_input = Input(shape=(24,104),  name = \"timeseries_input\")\n",
        "    input_embeddings = Input(shape=(ner_limit, input_dimension), name = \"cnn_input\")\n",
        "\n",
        "\n",
        "    # 3 1D convolutional layers, with no padding\n",
        "    text_conv1d = Conv1D(filters=num_filter[0], kernel_size=3,\n",
        "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                         kernel_initializer=GlorotUniform() )(input_embeddings)\n",
        "\n",
        "    text_conv1d = Conv1D(filters=num_filter[1], kernel_size=3,\n",
        "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                        kernel_initializer=GlorotUniform())(text_conv1d)\n",
        "\n",
        "    text_conv1d = Conv1D(filters=num_filter[2], kernel_size=3,\n",
        "                 padding = 'valid', strides = 1, dilation_rate=1, activation='relu',\n",
        "                        kernel_initializer=GlorotUniform())(text_conv1d)\n",
        "\n",
        "    # max pooling layer\n",
        "    text_embeddings = GlobalMaxPooling1D()(text_conv1d)\n",
        "\n",
        "    # GRU layer for time series data\n",
        "    x = GRU(number_of_unit)(ts_input)\n",
        "\n",
        "    # concatenate time series features and medical entity feature\n",
        "    concatenated = Concatenate(axis=1)([x, text_embeddings])\n",
        "\n",
        "    # Fully connected layer\n",
        "    concatenated = Dense(512, activation='relu')(concatenated)\n",
        "    concatenated = Dropout(0.2)(concatenated)\n",
        "\n",
        "    preds = Dense(1, activation='sigmoid',use_bias=False,\n",
        "                          kernel_initializer=GlorotUniform(),\n",
        "                  kernel_regularizer=L2(l2=0.01))(concatenated)\n",
        "\n",
        "    model = Model(inputs=[ts_input, input_embeddings], outputs=preds)\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=Adam(learning_rate=0.001),\n",
        "                  metrics=['acc'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "IG-9k9AjD_96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "77i5KzKZwYm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_scores(model, test_data, ground_truth):\n",
        "    \"\"\"\n",
        "    Prints auc, auprc and f1 scores to the screen.\n",
        "\n",
        "    Arguments:\n",
        "        model: the proposed model\n",
        "        test_data: testing data\n",
        "        ground_truth: the proposed model\n",
        "\n",
        "    Outputs:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # make predictions\n",
        "    probs = model.predict(test_data)\n",
        "    y_pred = [1 if i>=0.5 else 0 for i in probs]\n",
        "\n",
        "    #evaluate\n",
        "    auc = roc_auc_score(ground_truth, probs)\n",
        "    auprc = average_precision_score(ground_truth, probs)\n",
        "    acc   = accuracy_score(ground_truth, y_pred)\n",
        "    F1    = f1_score(ground_truth, y_pred)\n",
        "\n",
        "    print (\"AUC: \", auc, \"AUPRC: \", auprc, \"F1: \", F1)"
      ],
      "metadata": {
        "id": "hIvA1sizwYYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and evaluate Model\n"
      ],
      "metadata": {
        "id": "Sat7YhQ4VSKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def get_subvector_data(size, embed_name, data):\n",
        "    \"\"\"\n",
        "    Turn embeddings into matrix of the dimensions vector_size x size\n",
        "    \"\"\"\n",
        "    # specify vector size\n",
        "    if embed_name == \"concat\":\n",
        "        vector_size = 200\n",
        "    else:\n",
        "        vector_size = 100\n",
        "\n",
        "    x_data = {}\n",
        "    for k, v in data.items():\n",
        "        # get the number of additional vectors needed for padding\n",
        "        number_of_additional_vectors = len(v) - size\n",
        "        vector = []\n",
        "        for i in v:\n",
        "            vector.append(i)\n",
        "        # If vector length is less than required size, pad with zero vectors\n",
        "        # else, slice the vector to keep only the required size\n",
        "        if number_of_additional_vectors < 0:\n",
        "            number_of_additional_vectors = np.abs(number_of_additional_vectors)\n",
        "\n",
        "            temp = vector[:size]\n",
        "            for i in range(0, number_of_additional_vectors):\n",
        "                temp.append(np.zeros(vector_size))\n",
        "            x_data[k] = np.asarray(temp)\n",
        "        else:\n",
        "            x_data[k] = np.asarray(vector[:size])\n",
        "\n",
        "    return x_data\n",
        "\n",
        "\n",
        "## training\n",
        "\n",
        "print(\"\"\"-*--------------*-----------------*-----\n",
        "\n",
        "TRAINING ON SUBSET FOR DEMO PURPOSES ONLY\n",
        "\n",
        "----------*--------------*-------------------*----\"\"\")\n",
        "\n",
        "for embed_dict, embed_name in zip(embedding_dict, embedding_types):\n",
        "    print (\"Embedding: \", embed_name)\n",
        "    print(\"=============================\")\n",
        "\n",
        "    # split embeddings into training, validation and testing\n",
        "    temp_train_ner = dict((k, embed_dict[k]) for k in train_patients)\n",
        "    tem_val_ner = dict((k, embed_dict[k]) for k in val_patients)\n",
        "    temp_test_ner = dict((k, embed_dict[k]) for k in test_patients)\n",
        "\n",
        "    # combine medical entiy embeddings vertically, with padding, to create a patient matrix representation\n",
        "    x_train_dict = get_subvector_data(ner_representation_limit, embed_name, temp_train_ner)\n",
        "    x_val_dict = get_subvector_data(ner_representation_limit, embed_name, tem_val_ner)\n",
        "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, temp_test_ner)\n",
        "\n",
        "    x_train_dict_sorted = collections.OrderedDict(sorted(x_train_dict.items()))\n",
        "    x_val_dict_sorted = collections.OrderedDict(sorted(x_val_dict.items()))\n",
        "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
        "\n",
        "    x_train_ner = np.asarray(list(x_train_dict_sorted.values()))\n",
        "    x_val_ner = np.asarray(list(x_val_dict_sorted.values()))\n",
        "    x_test_ner = np.asarray(list(x_test_dict_sorted.values()))\n",
        "\n",
        "    # train model for each iteration and each problem\n",
        "    for iteration in range(1,maxiter):\n",
        "        print (\"Iteration number: \", iteration)\n",
        "\n",
        "        #set a different seed for each iteration (still get slightly different results with each run)\n",
        "        set_seed(SEED + iteration)\n",
        "\n",
        "        for each_problem in target_problems:\n",
        "            print (\"__________________\")\n",
        "            print (\"Problem type: \", each_problem)\n",
        "\n",
        "            # employ early stopping\n",
        "            early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n",
        "            callbacks = [early_stopping_monitor]\n",
        "\n",
        "            # load and train model\n",
        "            model = proposed_model(ts_hidden_unit,\n",
        "                               embed_name, ner_representation_limit,filter_sizes)\n",
        "            model.fit([x_train_ts, x_train_ner], y_train[each_problem],\n",
        "                      epochs=num_epoch, verbose=1,\n",
        "                      validation_data=([x_val_ts, x_val_ner], y_val[each_problem]),\n",
        "                      callbacks=callbacks, batch_size=batch_size)\n",
        "\n",
        "            # make predictions and evaluate\n",
        "            print_scores(model, [x_test_ts, x_test_ner], y_test[each_problem])\n",
        "\n",
        "            del model\n",
        "            clear_session()\n",
        "            gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY4hUez6V6Se",
        "outputId": "9dcbac6b-838d-4ec1-ca78-8e0b3e9f5736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-*--------------*-----------------*-----\n",
            "\n",
            "TRAINING ON SUBSET FOR DEMO PURPOSES ONLY\n",
            "\n",
            "----------*--------------*-------------------*----\n",
            "Embedding:  word2vec\n",
            "=============================\n",
            "Iteration number:  1\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 14ms/sample - loss: 0.5210 - acc: 0.8600 - val_loss: 0.6470 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.3104 - acc: 0.9400 - val_loss: 0.8141 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.2726 - acc: 0.9400 - val_loss: 0.8127 - val_acc: 0.8571\n",
            "AUC:  0.27777777777777773 AUPRC:  0.18888888888888888 F1:  0.0\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 0.5742 - acc: 0.7800 - val_loss: 0.6571 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.1101 - acc: 0.9800 - val_loss: 1.0154 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.1077 - acc: 0.9800 - val_loss: 1.2885 - val_acc: 0.8571\n",
            "AUC:  0.038461538461538436 AUPRC:  0.10512820512820513 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 2s 42ms/sample - loss: 0.8791 - acc: 0.3200 - val_loss: 2.2252 - val_acc: 0.2857\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 1s 20ms/sample - loss: 0.8540 - acc: 0.6200 - val_loss: 1.8676 - val_acc: 0.2857\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 1s 16ms/sample - loss: 0.6662 - acc: 0.6800 - val_loss: 1.2338 - val_acc: 0.2857\n",
            "AUC:  0.5535714285714286 AUPRC:  0.5665990259740259 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 10ms/sample - loss: 0.9422 - acc: 0.3600 - val_loss: 0.6065 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.2392 - acc: 0.9200 - val_loss: 0.9680 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.3204 - acc: 0.9200 - val_loss: 1.1781 - val_acc: 0.8571\n",
            "AUC:  0.7857142857142857 AUPRC:  0.25 F1:  0.0\n",
            "Embedding:  fasttext\n",
            "=============================\n",
            "Iteration number:  1\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 10ms/sample - loss: 0.4198 - acc: 0.8600 - val_loss: 1.1608 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.4102 - acc: 0.9400 - val_loss: 1.3228 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.3275 - acc: 0.9400 - val_loss: 1.1788 - val_acc: 0.8571\n",
            "AUC:  0.3888888888888889 AUPRC:  0.2102564102564103 F1:  0.0\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 10ms/sample - loss: 0.5436 - acc: 0.7400 - val_loss: 1.3131 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.1575 - acc: 0.9800 - val_loss: 1.9866 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.2061 - acc: 0.9800 - val_loss: 2.4130 - val_acc: 0.8571\n",
            "AUC:  0.11538461538461536 AUPRC:  0.11309523809523808 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 1.1440 - acc: 0.4800 - val_loss: 3.5360 - val_acc: 0.2857\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 1.6337 - acc: 0.6200 - val_loss: 3.1625 - val_acc: 0.2857\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 1.1835 - acc: 0.6200 - val_loss: 1.8918 - val_acc: 0.1429\n",
            "AUC:  0.5892857142857143 AUPRC:  0.5749323593073593 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 16ms/sample - loss: 1.2592 - acc: 0.2200 - val_loss: 0.9472 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 3ms/sample - loss: 0.4664 - acc: 0.9200 - val_loss: 1.5085 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 3ms/sample - loss: 0.5694 - acc: 0.9200 - val_loss: 1.7661 - val_acc: 0.8571\n",
            "AUC:  0.9285714285714286 AUPRC:  0.5 F1:  0.0\n",
            "Embedding:  concat\n",
            "=============================\n",
            "Iteration number:  1\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 0.3749 - acc: 0.9200 - val_loss: 1.0586 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.3764 - acc: 0.9400 - val_loss: 1.1482 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.2763 - acc: 0.9400 - val_loss: 0.9697 - val_acc: 0.8571\n",
            "AUC:  0.4722222222222222 AUPRC:  0.3121693121693122 F1:  0.0\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 0.5654 - acc: 0.8000 - val_loss: 0.9343 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.1256 - acc: 0.9800 - val_loss: 1.4702 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.1747 - acc: 0.9800 - val_loss: 1.8237 - val_acc: 0.8571\n",
            "AUC:  0.11538461538461536 AUPRC:  0.11309523809523808 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 1.0305 - acc: 0.4000 - val_loss: 3.1529 - val_acc: 0.2857\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 1.2694 - acc: 0.6200 - val_loss: 2.4258 - val_acc: 0.2857\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.9244 - acc: 0.6200 - val_loss: 1.2818 - val_acc: 0.1429\n",
            "AUC:  0.48214285714285715 AUPRC:  0.5323232323232323 F1:  0.0\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "Train on 50 samples, validate on 7 samples\n",
            "Epoch 1/3\n",
            "50/50 [==============================] - 1s 11ms/sample - loss: 1.3321 - acc: 0.1600 - val_loss: 0.6446 - val_acc: 0.8571\n",
            "Epoch 2/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.3753 - acc: 0.9200 - val_loss: 1.0902 - val_acc: 0.8571\n",
            "Epoch 3/3\n",
            "50/50 [==============================] - 0s 2ms/sample - loss: 0.5329 - acc: 0.9200 - val_loss: 1.2988 - val_acc: 0.8571\n",
            "AUC:  0.9285714285714286 AUPRC:  0.5 F1:  0.0\n",
            "CPU times: user 38.9 s, sys: 614 ms, total: 39.6 s\n",
            "Wall time: 38.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del concatenated_embeddings, val_patients, embed_dict, embed_name, embedding_dict\n",
        "del patients,patients_val, patients_test, patients_to_keep, patients_train, tem_val_ner\n",
        "del temp_test_ner,temp_train_ner,test_patients,word2vec_embeddings\n",
        "del x_val_dict,x_val_dict_sorted,x_val_ner,x_val_ts,x_test_dict,x_test_dict_sorted\n",
        "del x_test_ner,x_test_ts,x_train_dict,x_train_dict_sorted,x_train_ner,x_train_ts,\n",
        "del y_val, y_test,y_train\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "L_NVPrKvLJ2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c98698-f701-4d7a-954a-ba8d3085478d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking that the whole notebook does not exceed 8 mins (not hard rule but needs to run fast))\n",
        "print(\"Total running time = {:.2f} minutes\".format((time.time() - _START_RUNTIME)/60))"
      ],
      "metadata": {
        "id": "LT_xdLhEljPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737df081-2519-4a56-cb8f-a789036f6ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total running time = 6.24 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results\n",
        "This section includes:\n",
        "\n",
        "1. For demo purposes, the pretrained models (trained outside this notebook) are loaded and tested. These models are the best models from the last (10th) iteration.\n",
        "2. Table of results for the proposed model (average of all 10 iterations)\n",
        "    - All claims are supported by experiment results\n",
        "    - Discussion with respect to the hypothesis and results from the original paper\n",
        "3. Ablation Study.\n",
        "\n",
        "The results are all reported with AUROC (AUC), AUPRC and F1."
      ],
      "metadata": {
        "id": "gX6bCcZNuxmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Proposed Model"
      ],
      "metadata": {
        "id": "FGO9iwhUzTPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained model and preprocessed data"
      ],
      "metadata": {
        "id": "HDllp1ZEF8ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_processed_data(raw_data_dir):\n",
        "    \"\"\"load the full processed testing data\"\"\"\n",
        "    # load time series data\n",
        "    x_test_ts= pd.read_pickle(f\"{raw_data_dir}/full_x_test.pkl\")\n",
        "    y_test = pd.read_pickle(f\"{raw_data_dir}/full_y_test.pkl\")\n",
        "\n",
        "    test_patients = y_test.index.get_level_values('subject_id')\n",
        "\n",
        "    # loading full embeddings, but only keeping test patients\n",
        "    word2vec_embeddings_test = pd.read_pickle(f\"{raw_data_dir}/full_word2vec_embeddings.pkl\")\n",
        "    word2vec_embeddings_test = dict((k, word2vec_embeddings_test[k]) for k in test_patients)\n",
        "\n",
        "    fasttext_embeddings_test = pd.read_pickle(f\"{raw_data_dir}/full_fasttext_embeddings.pkl\")\n",
        "    fasttext_embeddings_test = dict((k, fasttext_embeddings_test[k]) for k in test_patients)\n",
        "\n",
        "    concat_embeddings_test = pd.read_pickle(f\"{raw_data_dir}/full_concat_embeddings.pkl\")\n",
        "    concat_embeddings_test = dict((k, concat_embeddings_test[k]) for k in test_patients)\n",
        "\n",
        "    return x_test_ts, y_test, word2vec_embeddings_test, fasttext_embeddings_test , concat_embeddings_test\n",
        "\n",
        "\n",
        "# load processed data\n",
        "x_test_ts, y_test, word2vec_embeddings_test, fasttext_embeddings_test, concat_embeddings_test = load_processed_data(DATA_PATH)\n"
      ],
      "metadata": {
        "id": "LY4xvutqOYDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_types = ['word2vec', 'fasttext', 'concat']\n",
        "embedding_dict = [word2vec_embeddings_test, fasttext_embeddings_test, concat_embeddings_test]\n",
        "target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n",
        "iteration = 0 # only saved the best model model from the last iteration\n",
        "\n",
        "# load best 10nth iteration pretrained models and evaluate on testing data\n",
        "for embed_dict, embed_name in zip(embedding_dict, embedding_types):\n",
        "    print (\"\\n Embedding: \", embed_name)\n",
        "    print(\"=============================\")\n",
        "\n",
        "    x_test_dict = get_subvector_data(ner_representation_limit, embed_name, embed_dict)\n",
        "    x_test_dict_sorted = collections.OrderedDict(sorted(x_test_dict.items()))\n",
        "    x_test_ner = np.asarray(list(x_test_dict_sorted.values()))\n",
        "\n",
        "    for each_problem in target_problems:\n",
        "        print (\"__________________\")\n",
        "        print (\"Problem type: \", each_problem)\n",
        "\n",
        "        # create a model instance\n",
        "        pretrained_model = proposed_model(ts_hidden_unit,\n",
        "                            embed_name, ner_representation_limit,filter_sizes)\n",
        "\n",
        "        # Load the weights\n",
        "        pretrained_model.load_weights(f\"{RESULTS_PATH}/64-basiccnn1d-{embed_name}-{each_problem}-best_model.hdf5\")\n",
        "\n",
        "        # print metrics to evaluate model\n",
        "        print_scores(pretrained_model, [x_test_ts, x_test_ner], y_test[each_problem])"
      ],
      "metadata": {
        "id": "HtiqjqNyHHWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2073157-9bb2-4fdd-cafa-3158fae41c3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Embedding:  word2vec\n",
            "=============================\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "AUC:  0.8753810934554268 AUPRC:  0.5644586051009224 F1:  0.4621733149931225\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "AUC:  0.8803528881447615 AUPRC:  0.5191799884847719 F1:  0.4733475479744136\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "AUC:  0.7064488719993578 AUPRC:  0.6464571955831138 F1:  0.5618848792126454\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "AUC:  0.730345793252078 AUPRC:  0.22082511832769958 F1:  0.02197802197802198\n",
            "\n",
            " Embedding:  fasttext\n",
            "=============================\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "AUC:  0.8714225693509292 AUPRC:  0.5524502560820251 F1:  0.46433566433566437\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "AUC:  0.8781734021446816 AUPRC:  0.5074139181918761 F1:  0.4562899786780384\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "AUC:  0.6996246688254342 AUPRC:  0.6408740851149082 F1:  0.5552256532066507\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "AUC:  0.7257790637790927 AUPRC:  0.2059790210232904 F1:  0.011111111111111112\n",
            "\n",
            " Embedding:  concat\n",
            "=============================\n",
            "__________________\n",
            "Problem type:  mort_hosp\n",
            "AUC:  0.8731968758416375 AUPRC:  0.5568439681603272 F1:  0.44381223328591746\n",
            "__________________\n",
            "Problem type:  mort_icu\n",
            "AUC:  0.8841491648497893 AUPRC:  0.5184273944700841 F1:  0.4595744680851064\n",
            "__________________\n",
            "Problem type:  los_3\n",
            "AUC:  0.7055270609762625 AUPRC:  0.6463226725685567 F1:  0.5634472511144131\n",
            "__________________\n",
            "Problem type:  los_7\n",
            "AUC:  0.7197721323331203 AUPRC:  0.21898023646470968 F1:  0.011111111111111112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Table of results and comparison"
      ],
      "metadata": {
        "id": "KTi19SRldQH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved original paper results as reported\n",
        "reported_results = pd.read_csv(f\"{RESULTS_PATH}/reported_results.csv\")\n",
        "\n",
        "#display(reported_results.head(12))\n",
        "\n",
        "# load the saved experiment results for all models and iterations\n",
        "full_results = pd.read_csv(f\"{RESULTS_PATH}/results.csv\")\n",
        "# printing the word2vec results from the 10nth iteration as they match above model results\n",
        "full_results[(full_results['Model'] == 'Proposed') & (full_results['Embedding'] == 'word2vec') & (full_results['Iteration'] == 10)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "YCt6xmONdPkc",
        "outputId": "118362a8-a19c-48c9-8cb6-0dd4fad26a54"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Task     Model Embedding  Iteration       AUC     AUPRC       ACC  \\\n",
              "36  mort_hosp  Proposed  word2vec         10  0.875381  0.564459  0.911538   \n",
              "37   mort_icu  Proposed  word2vec         10  0.880353  0.519180  0.944118   \n",
              "38      los_3  Proposed  word2vec         10  0.706449  0.646457  0.667647   \n",
              "39      los_7  Proposed  word2vec         10  0.730346  0.220825  0.919457   \n",
              "\n",
              "          F1  \n",
              "36  0.462173  \n",
              "37  0.473348  \n",
              "38  0.561885  \n",
              "39  0.021978  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b669b4e-b0be-45c5-827f-3c7f18c761a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task</th>\n",
              "      <th>Model</th>\n",
              "      <th>Embedding</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>ACC</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>mort_hosp</td>\n",
              "      <td>Proposed</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>10</td>\n",
              "      <td>0.875381</td>\n",
              "      <td>0.564459</td>\n",
              "      <td>0.911538</td>\n",
              "      <td>0.462173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>mort_icu</td>\n",
              "      <td>Proposed</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>10</td>\n",
              "      <td>0.880353</td>\n",
              "      <td>0.519180</td>\n",
              "      <td>0.944118</td>\n",
              "      <td>0.473348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>los_3</td>\n",
              "      <td>Proposed</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>10</td>\n",
              "      <td>0.706449</td>\n",
              "      <td>0.646457</td>\n",
              "      <td>0.667647</td>\n",
              "      <td>0.561885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>los_7</td>\n",
              "      <td>Proposed</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>10</td>\n",
              "      <td>0.730346</td>\n",
              "      <td>0.220825</td>\n",
              "      <td>0.919457</td>\n",
              "      <td>0.021978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b669b4e-b0be-45c5-827f-3c7f18c761a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9b669b4e-b0be-45c5-827f-3c7f18c761a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9b669b4e-b0be-45c5-827f-3c7f18c761a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c4359cd0-e0c5-4cea-b3ce-bd2550408e03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c4359cd0-e0c5-4cea-b3ce-bd2550408e03')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c4359cd0-e0c5-4cea-b3ce-bd2550408e03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"full_results[(full_results['Model'] == 'Proposed') & (full_results['Embedding'] == 'word2vec') & (full_results['Iteration'] == 10)]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"mort_icu\",\n          \"los_7\",\n          \"mort_hosp\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Proposed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embedding\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"word2vec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Iteration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 10,\n        \"max\": 10,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0926074931427538,\n        \"min\": 0.706448977,\n        \"max\": 0.880352888,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.880352888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1855702197333908,\n        \"min\": 0.220825118,\n        \"max\": 0.646457196,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.519179988\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ACC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12944094841035875,\n        \"min\": 0.667647059,\n        \"max\": 0.944117647,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.944117647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24271242889400116,\n        \"min\": 0.021978022,\n        \"max\": 0.561884879,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.473347548\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace tasks as in paper\n",
        "task_map = {\n",
        "    \"los_3\": \"LOS >3 days\",\n",
        "    \"los_7\": \"LOS >7 days\",\n",
        "    \"mort_hosp\": \"In-hospital mortality\",\n",
        "    \"mort_icu\": \"In-ICU mortality\"\n",
        "}\n",
        "full_results[\"Task\"] = full_results[\"Task\"].map(task_map)\n",
        "full_results['Embedding'] = full_results['Embedding'].replace('', np.nan).fillna('-')\n",
        "reported_results[\"Task\"] = reported_results[\"Task\"].map(task_map)\n",
        "\n",
        "# save the standard deviation for explanation\n",
        "results_std = full_results.groupby(['Task', 'Model', 'Embedding']).agg(AUC_std=('AUC', 'std'),\n",
        "                                                                       AUPRC_std=('AUPRC', 'std'),\n",
        "                                                                       F1_std=('F1', 'std')).round(4)*100\n",
        "results_std.reset_index(inplace=True)\n",
        "\n",
        "# average the results from the 10 iterations\n",
        "\n",
        "full_results.drop(columns=['Iteration','ACC'],inplace=True)\n",
        "full_results = full_results.groupby(['Task', 'Model', 'Embedding']).mean().round(4)*100\n",
        "full_results.reset_index(inplace=True)\n",
        "\n",
        "# only retain the proposed model results\n",
        "proposed_model_results = full_results[full_results['Model'] == 'Proposed']\n",
        "#proposed_model_results"
      ],
      "metadata": {
        "id": "X90J1KmMG6id"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Scores"
      ],
      "metadata": {
        "id": "fWwVN-pFVZS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare and display table of results\n",
        "proposed_model_comparison = pd.merge(proposed_model_results.drop(columns=['Model']),\n",
        "                                     reported_results[reported_results['Model'] == 'Proposed (Reported)'].drop(columns=['Model','AUC_std','AUPRC_std','F1_std']),\n",
        "                                     on=['Task','Embedding'], suffixes=('', '_reported'))\n",
        "\n",
        "## calculate the difference in scores\n",
        "proposed_model_comparison['AUC_diff'] = proposed_model_comparison['AUC'] - proposed_model_comparison['AUC_reported']\n",
        "proposed_model_comparison['AUPRC_diff'] = proposed_model_comparison['AUPRC'] - proposed_model_comparison['AUPRC_reported']\n",
        "proposed_model_comparison['F1_diff'] = proposed_model_comparison['F1'] - proposed_model_comparison['F1_reported']\n",
        "proposed_model_comparison = proposed_model_comparison[['Task','Embedding','AUC','AUC_reported','AUC_diff','AUPRC',\n",
        "                                                      'AUPRC_reported','AUPRC_diff','F1','F1_reported','F1_diff']]\n",
        "proposed_model_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "b5OoedrTpLG1",
        "outputId": "7803cc79-6a84-44d6-e62c-b377c2c71503"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Task Embedding    AUC  AUC_reported  AUC_diff  AUPRC  \\\n",
              "0        In-ICU mortality    concat  87.79         87.66      0.13  50.37   \n",
              "1        In-ICU mortality  fasttext  87.19         87.85     -0.66  49.70   \n",
              "2        In-ICU mortality  word2vec  87.47         88.35     -0.88  50.23   \n",
              "3   In-hospital mortality    concat  87.43         86.98      0.45  56.65   \n",
              "4   In-hospital mortality  fasttext  87.15         87.15      0.00  56.06   \n",
              "5   In-hospital mortality  word2vec  87.46         87.55     -0.09  56.89   \n",
              "6             LOS >3 days    concat  70.03         69.93      0.10  63.95   \n",
              "7             LOS >3 days  fasttext  69.63         69.64     -0.01  63.70   \n",
              "8             LOS >3 days  word2vec  70.06         69.54      0.52  64.23   \n",
              "9             LOS >7 days    concat  71.38         71.92     -0.54  20.70   \n",
              "10            LOS >7 days  fasttext  71.74         71.81     -0.07  20.53   \n",
              "11            LOS >7 days  word2vec  72.14         72.55     -0.41  21.01   \n",
              "\n",
              "    AUPRC_reported  AUPRC_diff     F1  F1_reported  F1_diff  \n",
              "0            48.74        1.63  40.50        42.24    -1.74  \n",
              "1            48.78        0.92  39.16        43.09    -3.93  \n",
              "2            49.23        1.00  40.97        43.02    -2.05  \n",
              "3            55.35        1.30  45.17        46.38    -1.21  \n",
              "4            55.68        0.38  44.79        46.87    -2.08  \n",
              "5            55.87        1.02  45.42        47.23    -1.81  \n",
              "6            62.77        1.18  55.71        55.82    -0.11  \n",
              "7            62.55        1.15  54.46        55.87    -1.41  \n",
              "8            62.68        1.55  55.21        55.82    -0.61  \n",
              "9            18.25        2.45   3.37         1.38     1.99  \n",
              "10           18.01        2.52   1.76         1.08     0.68  \n",
              "11           18.78        2.23   1.74         1.58     0.16  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6714a4f3-f8d5-4a6d-b252-b25db8490ef4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task</th>\n",
              "      <th>Embedding</th>\n",
              "      <th>AUC</th>\n",
              "      <th>AUC_reported</th>\n",
              "      <th>AUC_diff</th>\n",
              "      <th>AUPRC</th>\n",
              "      <th>AUPRC_reported</th>\n",
              "      <th>AUPRC_diff</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1_reported</th>\n",
              "      <th>F1_diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>concat</td>\n",
              "      <td>87.79</td>\n",
              "      <td>87.66</td>\n",
              "      <td>0.13</td>\n",
              "      <td>50.37</td>\n",
              "      <td>48.74</td>\n",
              "      <td>1.63</td>\n",
              "      <td>40.50</td>\n",
              "      <td>42.24</td>\n",
              "      <td>-1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>87.19</td>\n",
              "      <td>87.85</td>\n",
              "      <td>-0.66</td>\n",
              "      <td>49.70</td>\n",
              "      <td>48.78</td>\n",
              "      <td>0.92</td>\n",
              "      <td>39.16</td>\n",
              "      <td>43.09</td>\n",
              "      <td>-3.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>87.47</td>\n",
              "      <td>88.35</td>\n",
              "      <td>-0.88</td>\n",
              "      <td>50.23</td>\n",
              "      <td>49.23</td>\n",
              "      <td>1.00</td>\n",
              "      <td>40.97</td>\n",
              "      <td>43.02</td>\n",
              "      <td>-2.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>concat</td>\n",
              "      <td>87.43</td>\n",
              "      <td>86.98</td>\n",
              "      <td>0.45</td>\n",
              "      <td>56.65</td>\n",
              "      <td>55.35</td>\n",
              "      <td>1.30</td>\n",
              "      <td>45.17</td>\n",
              "      <td>46.38</td>\n",
              "      <td>-1.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>87.15</td>\n",
              "      <td>87.15</td>\n",
              "      <td>0.00</td>\n",
              "      <td>56.06</td>\n",
              "      <td>55.68</td>\n",
              "      <td>0.38</td>\n",
              "      <td>44.79</td>\n",
              "      <td>46.87</td>\n",
              "      <td>-2.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>87.46</td>\n",
              "      <td>87.55</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>56.89</td>\n",
              "      <td>55.87</td>\n",
              "      <td>1.02</td>\n",
              "      <td>45.42</td>\n",
              "      <td>47.23</td>\n",
              "      <td>-1.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>concat</td>\n",
              "      <td>70.03</td>\n",
              "      <td>69.93</td>\n",
              "      <td>0.10</td>\n",
              "      <td>63.95</td>\n",
              "      <td>62.77</td>\n",
              "      <td>1.18</td>\n",
              "      <td>55.71</td>\n",
              "      <td>55.82</td>\n",
              "      <td>-0.11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>69.63</td>\n",
              "      <td>69.64</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>63.70</td>\n",
              "      <td>62.55</td>\n",
              "      <td>1.15</td>\n",
              "      <td>54.46</td>\n",
              "      <td>55.87</td>\n",
              "      <td>-1.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>70.06</td>\n",
              "      <td>69.54</td>\n",
              "      <td>0.52</td>\n",
              "      <td>64.23</td>\n",
              "      <td>62.68</td>\n",
              "      <td>1.55</td>\n",
              "      <td>55.21</td>\n",
              "      <td>55.82</td>\n",
              "      <td>-0.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>concat</td>\n",
              "      <td>71.38</td>\n",
              "      <td>71.92</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>20.70</td>\n",
              "      <td>18.25</td>\n",
              "      <td>2.45</td>\n",
              "      <td>3.37</td>\n",
              "      <td>1.38</td>\n",
              "      <td>1.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>71.74</td>\n",
              "      <td>71.81</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>20.53</td>\n",
              "      <td>18.01</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1.76</td>\n",
              "      <td>1.08</td>\n",
              "      <td>0.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>72.14</td>\n",
              "      <td>72.55</td>\n",
              "      <td>-0.41</td>\n",
              "      <td>21.01</td>\n",
              "      <td>18.78</td>\n",
              "      <td>2.23</td>\n",
              "      <td>1.74</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6714a4f3-f8d5-4a6d-b252-b25db8490ef4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6714a4f3-f8d5-4a6d-b252-b25db8490ef4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6714a4f3-f8d5-4a6d-b252-b25db8490ef4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6ae0aa2b-612f-4390-9ba7-248a479972d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6ae0aa2b-612f-4390-9ba7-248a479972d3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6ae0aa2b-612f-4390-9ba7-248a479972d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "proposed_model_comparison",
              "summary": "{\n  \"name\": \"proposed_model_comparison\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"In-hospital mortality\",\n          \"LOS >7 days\",\n          \"In-ICU mortality\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embedding\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"concat\",\n          \"fasttext\",\n          \"word2vec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.691547748975855,\n        \"min\": 69.63000000000001,\n        \"max\": 87.79,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          71.74000000000001,\n          71.38,\n          87.79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.769895260422889,\n        \"min\": 69.54,\n        \"max\": 88.35,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          71.81,\n          71.92,\n          87.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42693055286509446,\n        \"min\": -0.8799999999999955,\n        \"max\": 0.519999999999996,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          -0.06999999999999318,\n          -0.5400000000000063,\n          0.13000000000000966\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.121564552553973,\n        \"min\": 20.53,\n        \"max\": 64.23,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          20.53,\n          20.7,\n          50.370000000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17.65880283100308,\n        \"min\": 18.01,\n        \"max\": 62.77,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          18.01,\n          18.25,\n          48.74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.660157809416304,\n        \"min\": 0.38000000000000256,\n        \"max\": 2.5199999999999996,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.5199999999999996,\n          2.4499999999999993,\n          1.6300000000000026\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20.91754845418873,\n        \"min\": 1.7399999999999998,\n        \"max\": 55.71,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          1.76,\n          3.37,\n          40.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21.883611897878506,\n        \"min\": 1.08,\n        \"max\": 55.87,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          47.23,\n          42.24,\n          1.08\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.546867803013561,\n        \"min\": -3.9299999999999997,\n        \"max\": 1.9900000000000002,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          0.6799999999999999,\n          1.9900000000000002,\n          -1.740000000000002\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standard Deviation"
      ],
      "metadata": {
        "id": "SxXCpM0IVbue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proposed_model_comparison = pd.merge(results_std[(results_std['Model'] == 'Proposed')].drop(columns=['Model']),\n",
        "                                     reported_results[reported_results['Model'] == 'Proposed (Reported)'].drop(columns=['Model','AUC','AUPRC','F1']),\n",
        "                                     on=['Task','Embedding'], suffixes=('', '_reported'))\n",
        "proposed_model_comparison = proposed_model_comparison[['Task','Embedding','AUC_std','AUC_std_reported','AUPRC_std',\n",
        "                                                      'AUPRC_std_reported','F1_std','F1_std_reported']]\n",
        "proposed_model_comparison"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "gWA48hbSxd8g",
        "outputId": "650c079d-5744-45c6-a0b8-d354d6514f7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Task Embedding  AUC_std  AUC_std_reported  AUPRC_std  \\\n",
              "0        In-ICU mortality    concat     0.71             0.002       1.48   \n",
              "1        In-ICU mortality  fasttext     0.57             0.001       1.30   \n",
              "2        In-ICU mortality  word2vec     0.51             0.002       1.43   \n",
              "3   In-hospital mortality    concat     0.44             0.003       0.79   \n",
              "4   In-hospital mortality  fasttext     0.44             0.002       0.94   \n",
              "5   In-hospital mortality  word2vec     0.57             0.003       0.69   \n",
              "6             LOS >3 days    concat     0.46             0.001       0.59   \n",
              "7             LOS >3 days  fasttext     0.44             0.003       0.75   \n",
              "8             LOS >3 days  word2vec     0.63             0.002       0.94   \n",
              "9             LOS >7 days    concat     1.54             0.007       0.96   \n",
              "10            LOS >7 days  fasttext     1.13             0.004       1.24   \n",
              "11            LOS >7 days  word2vec     1.13             0.005       1.01   \n",
              "\n",
              "    AUPRC_std_reported  F1_std  F1_std_reported  \n",
              "0                0.009    5.81            0.027  \n",
              "1                0.009    4.03            0.026  \n",
              "2                0.008    4.26            0.029  \n",
              "3                0.008    1.83            0.027  \n",
              "4                0.005    2.37            0.015  \n",
              "5                0.008    1.62            0.014  \n",
              "6                0.002    2.60            0.008  \n",
              "7                0.003    2.48            0.017  \n",
              "8                0.003    2.71            0.012  \n",
              "9                0.006    4.39            0.009  \n",
              "10               0.004    2.10            0.008  \n",
              "11               0.006    1.31            0.001  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6edca1e-0a3a-44ce-a777-2b47722e6e44\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task</th>\n",
              "      <th>Embedding</th>\n",
              "      <th>AUC_std</th>\n",
              "      <th>AUC_std_reported</th>\n",
              "      <th>AUPRC_std</th>\n",
              "      <th>AUPRC_std_reported</th>\n",
              "      <th>F1_std</th>\n",
              "      <th>F1_std_reported</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>concat</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.002</td>\n",
              "      <td>1.48</td>\n",
              "      <td>0.009</td>\n",
              "      <td>5.81</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.001</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0.009</td>\n",
              "      <td>4.03</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.002</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0.008</td>\n",
              "      <td>4.26</td>\n",
              "      <td>0.029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>concat</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.83</td>\n",
              "      <td>0.027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.005</td>\n",
              "      <td>2.37</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.008</td>\n",
              "      <td>1.62</td>\n",
              "      <td>0.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>concat</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.002</td>\n",
              "      <td>2.60</td>\n",
              "      <td>0.008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.003</td>\n",
              "      <td>2.48</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.003</td>\n",
              "      <td>2.71</td>\n",
              "      <td>0.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>concat</td>\n",
              "      <td>1.54</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.006</td>\n",
              "      <td>4.39</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.004</td>\n",
              "      <td>1.24</td>\n",
              "      <td>0.004</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>1.13</td>\n",
              "      <td>0.005</td>\n",
              "      <td>1.01</td>\n",
              "      <td>0.006</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6edca1e-0a3a-44ce-a777-2b47722e6e44')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6edca1e-0a3a-44ce-a777-2b47722e6e44 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6edca1e-0a3a-44ce-a777-2b47722e6e44');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35dd2439-a3eb-4303-a5a7-f97758a43a65\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35dd2439-a3eb-4303-a5a7-f97758a43a65')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35dd2439-a3eb-4303-a5a7-f97758a43a65 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "proposed_model_comparison",
              "summary": "{\n  \"name\": \"proposed_model_comparison\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"In-hospital mortality\",\n          \"LOS >7 days\",\n          \"In-ICU mortality\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embedding\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"concat\",\n          \"fasttext\",\n          \"word2vec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35780793053189186,\n        \"min\": 0.44,\n        \"max\": 1.54,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5700000000000001,\n          0.63,\n          0.7100000000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_std_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0017298624923456321,\n        \"min\": 0.001,\n        \"max\": 0.007,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.002,\n          0.001,\n          0.005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29254370302882643,\n        \"min\": 0.59,\n        \"max\": 1.48,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.69,\n          1.48,\n          1.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC_std_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0025030284687057626,\n        \"min\": 0.002,\n        \"max\": 0.009,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.009,\n          0.008,\n          0.006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.358725728784366,\n        \"min\": 1.31,\n        \"max\": 5.81,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2.1,\n          4.390000000000001,\n          5.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_std_reported\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009219133594998189,\n        \"min\": 0.001,\n        \"max\": 0.029,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.009,\n          0.026,\n          0.008\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discussion: Original paper result comparison\n",
        "\n",
        "**NOTE:** results with respect to the hypothesis will be discussed under ablations.\n",
        "\n",
        "1. For AUC, we reproduced scores to be within 1% of the reported values.\n",
        "2. The AUPRC scores were all higher than the reported values within 3%, with LOS > 7 days having the largest deviation.\n",
        "2. All F1 scores, except for LOS > 7 days are lower than the reported value within 4%. LOS > 7 days has a higher F1 score than reported, within 2%.\n",
        "\n",
        "Based on AUC and AUPRC, the results uphold the paper’s conclusion that the proposed model performs better than the reported baseline for these metrics. However, experiment F1 scores refute the paper's conclusion on all F1 scores except LOS > 7 days.\n",
        "\n",
        "However, the standard deviations of our experiments are much higher than the paper. The experiment standard deviations were between 0.44% and 5.81% while the paper reported between 0.001% and 0.029% standard deviation. Most reported results are within the standard deviation of the experiment results, so it is possible to get the same results as reported, by chance."
      ],
      "metadata": {
        "id": "ZOx3iRsn3EN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation Study\n",
        "\n",
        "Ablations are done based on the hypothesis:\n",
        "- Model trained without time series/ with medical entities only (assess the effect of multimodal approach)\n",
        "- Model trained without medical entities/with time series only (assess the effect of multimodal approach)\n",
        "- Model trained without convolution on medical entities (assess the effect of the convolution layer)\n",
        "\n",
        "The ablations are geared at isolating the effect of the multimodal approach and the different techniques (word embeddings and convolution) on the unstructured clinical notes in the final proposed model.\n",
        "\n",
        "See notebook: \"Ablations.ipynb\"\n",
        "\n",
        "The averaged results for the 10 iterations are displayed."
      ],
      "metadata": {
        "id": "EyqQzfDbPmcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def highlight_max_group(group):\n",
        "    \"\"\"highlight the maximum score in the group\"\"\"\n",
        "    return ['background-color: orange' if v == group.max() else '' for v in group]"
      ],
      "metadata": {
        "id": "SZT8GF5-2jlv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect of Convolution\n",
        "\n",
        "To assess the effect of the convolutional layers, we remove these layers and average the embeddings instead. This model is referred to as *No Convolution*.\n",
        "\n",
        "After removing convolution, the model performed better on all scores except length of stay AUPRC (see table below, the best scores are highlighted in orange).\n",
        "\n",
        "This challenges the effectiveness of the convolution, and the papers claims that the proposed model outperforms a multimodal approach without convolution."
      ],
      "metadata": {
        "id": "o4o2NlelVQEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize HTML string\n",
        "html_output = \"<table style='border-collapse: collapse; border: 1px solid black;'>\"\n",
        "\n",
        "# Group by Task and apply highlighting, then add to the HTML output\n",
        "for i, (name, group) in enumerate(full_results.groupby(\"Task\")):\n",
        "    group.drop(group.columns[0], axis=1, inplace=True)\n",
        "    group = group[group['Model'].isin(['No Convolution','Proposed'])]\n",
        "    styled_group = group.style.apply(highlight_max_group, subset=[\"AUC\", \"AUPRC\", \"F1\"])\n",
        "    # format scores back to 2 decimal places and hide index\n",
        "    styled_group = styled_group.format({col: \"{:.4}\" for col in [\"AUC\", \"AUPRC\", \"F1\"]})\n",
        "    styled_group = styled_group.hide(axis=\"index\")\n",
        "    # Add title as task name\n",
        "    html_output += f\"<td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>{name}</td>\"\n",
        "    # Convert styled DataFrame to HTML and add to the output\n",
        "    html_output += f\"<td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'>{styled_group.to_html()}</td>\"\n",
        "    # Display only two tables in a row\n",
        "    if (i + 1) % 2 == 0:\n",
        "        html_output += \"</tr><tr>\"\n",
        "\n",
        "# Close table\n",
        "html_output += \"</table>\"\n",
        "display(HTML(html_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "WFcKkaF8TDlT",
        "outputId": "102499f3-d74b-4dbc-f6c6-97a8f05762a9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style='border-collapse: collapse; border: 1px solid black;'><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-ICU mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_ca187_row2_col2, #T_ca187_row2_col3, #T_ca187_row2_col4 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_ca187\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_ca187_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_ca187_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_ca187_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_ca187_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_ca187_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_ca187_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_ca187_row0_col2\" class=\"data row0 col2\" >88.03</td>\n",
              "      <td id=\"T_ca187_row0_col3\" class=\"data row0 col3\" >51.5</td>\n",
              "      <td id=\"T_ca187_row0_col4\" class=\"data row0 col4\" >42.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_ca187_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_ca187_row1_col2\" class=\"data row1 col2\" >87.52</td>\n",
              "      <td id=\"T_ca187_row1_col3\" class=\"data row1 col3\" >50.14</td>\n",
              "      <td id=\"T_ca187_row1_col4\" class=\"data row1 col4\" >40.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_ca187_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_ca187_row2_col2\" class=\"data row2 col2\" >88.1</td>\n",
              "      <td id=\"T_ca187_row2_col3\" class=\"data row2 col3\" >51.73</td>\n",
              "      <td id=\"T_ca187_row2_col4\" class=\"data row2 col4\" >42.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row3_col0\" class=\"data row3 col0\" >Proposed</td>\n",
              "      <td id=\"T_ca187_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_ca187_row3_col2\" class=\"data row3 col2\" >87.79</td>\n",
              "      <td id=\"T_ca187_row3_col3\" class=\"data row3 col3\" >50.37</td>\n",
              "      <td id=\"T_ca187_row3_col4\" class=\"data row3 col4\" >40.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row4_col0\" class=\"data row4 col0\" >Proposed</td>\n",
              "      <td id=\"T_ca187_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_ca187_row4_col2\" class=\"data row4 col2\" >87.19</td>\n",
              "      <td id=\"T_ca187_row4_col3\" class=\"data row4 col3\" >49.7</td>\n",
              "      <td id=\"T_ca187_row4_col4\" class=\"data row4 col4\" >39.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_ca187_row5_col0\" class=\"data row5 col0\" >Proposed</td>\n",
              "      <td id=\"T_ca187_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_ca187_row5_col2\" class=\"data row5 col2\" >87.47</td>\n",
              "      <td id=\"T_ca187_row5_col3\" class=\"data row5 col3\" >50.23</td>\n",
              "      <td id=\"T_ca187_row5_col4\" class=\"data row5 col4\" >40.97</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-hospital mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_1e665_row2_col2, #T_1e665_row2_col3, #T_1e665_row2_col4 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_1e665\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_1e665_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_1e665_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_1e665_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_1e665_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_1e665_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_1e665_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_1e665_row0_col2\" class=\"data row0 col2\" >87.38</td>\n",
              "      <td id=\"T_1e665_row0_col3\" class=\"data row0 col3\" >57.0</td>\n",
              "      <td id=\"T_1e665_row0_col4\" class=\"data row0 col4\" >44.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_1e665_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_1e665_row1_col2\" class=\"data row1 col2\" >87.21</td>\n",
              "      <td id=\"T_1e665_row1_col3\" class=\"data row1 col3\" >56.31</td>\n",
              "      <td id=\"T_1e665_row1_col4\" class=\"data row1 col4\" >43.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_1e665_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_1e665_row2_col2\" class=\"data row2 col2\" >87.62</td>\n",
              "      <td id=\"T_1e665_row2_col3\" class=\"data row2 col3\" >57.4</td>\n",
              "      <td id=\"T_1e665_row2_col4\" class=\"data row2 col4\" >45.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row3_col0\" class=\"data row3 col0\" >Proposed</td>\n",
              "      <td id=\"T_1e665_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_1e665_row3_col2\" class=\"data row3 col2\" >87.43</td>\n",
              "      <td id=\"T_1e665_row3_col3\" class=\"data row3 col3\" >56.65</td>\n",
              "      <td id=\"T_1e665_row3_col4\" class=\"data row3 col4\" >45.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row4_col0\" class=\"data row4 col0\" >Proposed</td>\n",
              "      <td id=\"T_1e665_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_1e665_row4_col2\" class=\"data row4 col2\" >87.15</td>\n",
              "      <td id=\"T_1e665_row4_col3\" class=\"data row4 col3\" >56.06</td>\n",
              "      <td id=\"T_1e665_row4_col4\" class=\"data row4 col4\" >44.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1e665_row5_col0\" class=\"data row5 col0\" >Proposed</td>\n",
              "      <td id=\"T_1e665_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_1e665_row5_col2\" class=\"data row5 col2\" >87.46</td>\n",
              "      <td id=\"T_1e665_row5_col3\" class=\"data row5 col3\" >56.89</td>\n",
              "      <td id=\"T_1e665_row5_col4\" class=\"data row5 col4\" >45.42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >3 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_623a8_row0_col2, #T_623a8_row0_col4, #T_623a8_row5_col3 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_623a8\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_623a8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_623a8_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_623a8_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_623a8_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_623a8_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_623a8_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_623a8_row0_col2\" class=\"data row0 col2\" >70.1</td>\n",
              "      <td id=\"T_623a8_row0_col3\" class=\"data row0 col3\" >64.05</td>\n",
              "      <td id=\"T_623a8_row0_col4\" class=\"data row0 col4\" >56.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_623a8_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_623a8_row1_col2\" class=\"data row1 col2\" >69.83</td>\n",
              "      <td id=\"T_623a8_row1_col3\" class=\"data row1 col3\" >63.77</td>\n",
              "      <td id=\"T_623a8_row1_col4\" class=\"data row1 col4\" >55.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_623a8_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_623a8_row2_col2\" class=\"data row2 col2\" >69.93</td>\n",
              "      <td id=\"T_623a8_row2_col3\" class=\"data row2 col3\" >63.84</td>\n",
              "      <td id=\"T_623a8_row2_col4\" class=\"data row2 col4\" >54.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row3_col0\" class=\"data row3 col0\" >Proposed</td>\n",
              "      <td id=\"T_623a8_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_623a8_row3_col2\" class=\"data row3 col2\" >70.03</td>\n",
              "      <td id=\"T_623a8_row3_col3\" class=\"data row3 col3\" >63.95</td>\n",
              "      <td id=\"T_623a8_row3_col4\" class=\"data row3 col4\" >55.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row4_col0\" class=\"data row4 col0\" >Proposed</td>\n",
              "      <td id=\"T_623a8_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_623a8_row4_col2\" class=\"data row4 col2\" >69.63</td>\n",
              "      <td id=\"T_623a8_row4_col3\" class=\"data row4 col3\" >63.7</td>\n",
              "      <td id=\"T_623a8_row4_col4\" class=\"data row4 col4\" >54.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_623a8_row5_col0\" class=\"data row5 col0\" >Proposed</td>\n",
              "      <td id=\"T_623a8_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_623a8_row5_col2\" class=\"data row5 col2\" >70.06</td>\n",
              "      <td id=\"T_623a8_row5_col3\" class=\"data row5 col3\" >64.23</td>\n",
              "      <td id=\"T_623a8_row5_col4\" class=\"data row5 col4\" >55.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >7 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_da7d6_row1_col4, #T_da7d6_row2_col2, #T_da7d6_row5_col3 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_da7d6\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_da7d6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_da7d6_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_da7d6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_da7d6_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_da7d6_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_da7d6_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_da7d6_row0_col2\" class=\"data row0 col2\" >71.12</td>\n",
              "      <td id=\"T_da7d6_row0_col3\" class=\"data row0 col3\" >19.29</td>\n",
              "      <td id=\"T_da7d6_row0_col4\" class=\"data row0 col4\" >2.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_da7d6_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_da7d6_row1_col2\" class=\"data row1 col2\" >72.14</td>\n",
              "      <td id=\"T_da7d6_row1_col3\" class=\"data row1 col3\" >20.15</td>\n",
              "      <td id=\"T_da7d6_row1_col4\" class=\"data row1 col4\" >3.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_da7d6_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_da7d6_row2_col2\" class=\"data row2 col2\" >72.48</td>\n",
              "      <td id=\"T_da7d6_row2_col3\" class=\"data row2 col3\" >20.94</td>\n",
              "      <td id=\"T_da7d6_row2_col4\" class=\"data row2 col4\" >2.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row3_col0\" class=\"data row3 col0\" >Proposed</td>\n",
              "      <td id=\"T_da7d6_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_da7d6_row3_col2\" class=\"data row3 col2\" >71.38</td>\n",
              "      <td id=\"T_da7d6_row3_col3\" class=\"data row3 col3\" >20.7</td>\n",
              "      <td id=\"T_da7d6_row3_col4\" class=\"data row3 col4\" >3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row4_col0\" class=\"data row4 col0\" >Proposed</td>\n",
              "      <td id=\"T_da7d6_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_da7d6_row4_col2\" class=\"data row4 col2\" >71.74</td>\n",
              "      <td id=\"T_da7d6_row4_col3\" class=\"data row4 col3\" >20.53</td>\n",
              "      <td id=\"T_da7d6_row4_col4\" class=\"data row4 col4\" >1.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_da7d6_row5_col0\" class=\"data row5 col0\" >Proposed</td>\n",
              "      <td id=\"T_da7d6_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_da7d6_row5_col2\" class=\"data row5 col2\" >72.14</td>\n",
              "      <td id=\"T_da7d6_row5_col3\" class=\"data row5 col3\" >21.01</td>\n",
              "      <td id=\"T_da7d6_row5_col4\" class=\"data row5 col4\" >1.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Group by Task and apply the highlighting without html\n",
        "# for name, group in full_results.groupby(\"Task\"):\n",
        "#     print (\"\\n\\n Task: \", name)\n",
        "#     print(\"=============================\")\n",
        "#     group.drop(group.columns[0], axis=1, inplace=True)\n",
        "#     group = group[group['Model'].isin(['No convolution','Proposed'])]\n",
        "#     styled_group = group.style.apply(highlight_max_group, subset=[\"AUC\", \"AUPRC\", \"F1\"])\n",
        "#     # format scores back to 2 decimal places and hide index\n",
        "#     styled_group = styled_group.format({col: \"{:.4}\" for col in [\"AUC\", \"AUPRC\", \"F1\"]})\n",
        "#     styled_group = styled_group.hide(axis=\"index\")\n",
        "#     display(styled_group)"
      ],
      "metadata": {
        "id": "_hfSTk6gVOap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Effect of Multimodal Approach\n",
        "\n",
        "To assess the effect of the multimodal approach, we further removed medical entities (refered to as *Time Series* model) and the time series features (refered to as *No Time Series* model, which contains averaged embeddings) respectively. This gives two unimodal models.\n",
        "\n",
        "The *No Medical Entities* model performed better on all length of stay > 7 days scores, and on mortality AUCs. Thus effectiveness of the medical entities can be verified for most tasks, but not as many as the paper reported.\n",
        "\n",
        "The *No Time Series* model deteriorates performance significantly (by at least 7%). This also further verifies the effectiveness of the multimodal approach for most tasks."
      ],
      "metadata": {
        "id": "CiqTAEEdYvXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize HTML string\n",
        "html_output = \"<table style='border-collapse: collapse; border: 1px solid black;'>\"\n",
        "\n",
        "# Group by Task and apply highlighting, then add to the HTML output\n",
        "for i, (name, group) in enumerate(full_results.groupby(\"Task\")):\n",
        "    group.drop(group.columns[0], axis=1, inplace=True)\n",
        "    group = group[~group['Model'].isin([\"Proposed (Tuned)\"])]\n",
        "    styled_group = group.style.apply(highlight_max_group, subset=[\"AUC\", \"AUPRC\", \"F1\"])\n",
        "    # format scores back to 2 decimal places and hide index\n",
        "    styled_group = styled_group.format({col: \"{:.4}\" for col in [\"AUC\", \"AUPRC\", \"F1\"]})\n",
        "    styled_group = styled_group.hide(axis=\"index\")\n",
        "    # Add title as task name\n",
        "    html_output += f\"<td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>{name}</td>\"\n",
        "    # Convert styled DataFrame to HTML and add to the output\n",
        "    html_output += f\"<td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'>{styled_group.to_html()}</td>\"\n",
        "    # Display only two tables in a row\n",
        "    if (i + 1) % 2 == 0:\n",
        "        html_output += \"</tr><tr>\"\n",
        "\n",
        "# Close table\n",
        "html_output += \"</table>\"\n",
        "display(HTML(html_output))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "yYG7LglSgI42",
        "outputId": "65e1c63f-7406-4a92-be28-90a4cab25ebf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style='border-collapse: collapse; border: 1px solid black;'><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-ICU mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_442cb_row2_col3, #T_442cb_row2_col4, #T_442cb_row9_col2 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_442cb\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_442cb_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_442cb_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_442cb_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_442cb_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_442cb_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_442cb_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_442cb_row0_col2\" class=\"data row0 col2\" >88.03</td>\n",
              "      <td id=\"T_442cb_row0_col3\" class=\"data row0 col3\" >51.5</td>\n",
              "      <td id=\"T_442cb_row0_col4\" class=\"data row0 col4\" >42.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_442cb_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_442cb_row1_col2\" class=\"data row1 col2\" >87.52</td>\n",
              "      <td id=\"T_442cb_row1_col3\" class=\"data row1 col3\" >50.14</td>\n",
              "      <td id=\"T_442cb_row1_col4\" class=\"data row1 col4\" >40.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_442cb_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_442cb_row2_col2\" class=\"data row2 col2\" >88.1</td>\n",
              "      <td id=\"T_442cb_row2_col3\" class=\"data row2 col3\" >51.73</td>\n",
              "      <td id=\"T_442cb_row2_col4\" class=\"data row2 col4\" >42.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row3_col0\" class=\"data row3 col0\" >No Time Series</td>\n",
              "      <td id=\"T_442cb_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_442cb_row3_col2\" class=\"data row3 col2\" >74.33</td>\n",
              "      <td id=\"T_442cb_row3_col3\" class=\"data row3 col3\" >20.72</td>\n",
              "      <td id=\"T_442cb_row3_col4\" class=\"data row3 col4\" >0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row4_col0\" class=\"data row4 col0\" >No Time Series</td>\n",
              "      <td id=\"T_442cb_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_442cb_row4_col2\" class=\"data row4 col2\" >72.39</td>\n",
              "      <td id=\"T_442cb_row4_col3\" class=\"data row4 col3\" >19.05</td>\n",
              "      <td id=\"T_442cb_row4_col4\" class=\"data row4 col4\" >0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row5_col0\" class=\"data row5 col0\" >No Time Series</td>\n",
              "      <td id=\"T_442cb_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_442cb_row5_col2\" class=\"data row5 col2\" >73.81</td>\n",
              "      <td id=\"T_442cb_row5_col3\" class=\"data row5 col3\" >22.38</td>\n",
              "      <td id=\"T_442cb_row5_col4\" class=\"data row5 col4\" >0.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row6_col0\" class=\"data row6 col0\" >Proposed</td>\n",
              "      <td id=\"T_442cb_row6_col1\" class=\"data row6 col1\" >concat</td>\n",
              "      <td id=\"T_442cb_row6_col2\" class=\"data row6 col2\" >87.79</td>\n",
              "      <td id=\"T_442cb_row6_col3\" class=\"data row6 col3\" >50.37</td>\n",
              "      <td id=\"T_442cb_row6_col4\" class=\"data row6 col4\" >40.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row7_col0\" class=\"data row7 col0\" >Proposed</td>\n",
              "      <td id=\"T_442cb_row7_col1\" class=\"data row7 col1\" >fasttext</td>\n",
              "      <td id=\"T_442cb_row7_col2\" class=\"data row7 col2\" >87.19</td>\n",
              "      <td id=\"T_442cb_row7_col3\" class=\"data row7 col3\" >49.7</td>\n",
              "      <td id=\"T_442cb_row7_col4\" class=\"data row7 col4\" >39.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row8_col0\" class=\"data row8 col0\" >Proposed</td>\n",
              "      <td id=\"T_442cb_row8_col1\" class=\"data row8 col1\" >word2vec</td>\n",
              "      <td id=\"T_442cb_row8_col2\" class=\"data row8 col2\" >87.47</td>\n",
              "      <td id=\"T_442cb_row8_col3\" class=\"data row8 col3\" >50.23</td>\n",
              "      <td id=\"T_442cb_row8_col4\" class=\"data row8 col4\" >40.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_442cb_row9_col0\" class=\"data row9 col0\" >Time Series</td>\n",
              "      <td id=\"T_442cb_row9_col1\" class=\"data row9 col1\" >-</td>\n",
              "      <td id=\"T_442cb_row9_col2\" class=\"data row9 col2\" >88.5</td>\n",
              "      <td id=\"T_442cb_row9_col3\" class=\"data row9 col3\" >51.09</td>\n",
              "      <td id=\"T_442cb_row9_col4\" class=\"data row9 col4\" >41.31</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-hospital mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_389f6_row2_col3, #T_389f6_row2_col4, #T_389f6_row9_col2 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_389f6\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_389f6_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_389f6_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_389f6_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_389f6_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_389f6_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_389f6_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_389f6_row0_col2\" class=\"data row0 col2\" >87.38</td>\n",
              "      <td id=\"T_389f6_row0_col3\" class=\"data row0 col3\" >57.0</td>\n",
              "      <td id=\"T_389f6_row0_col4\" class=\"data row0 col4\" >44.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_389f6_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_389f6_row1_col2\" class=\"data row1 col2\" >87.21</td>\n",
              "      <td id=\"T_389f6_row1_col3\" class=\"data row1 col3\" >56.31</td>\n",
              "      <td id=\"T_389f6_row1_col4\" class=\"data row1 col4\" >43.86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_389f6_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_389f6_row2_col2\" class=\"data row2 col2\" >87.62</td>\n",
              "      <td id=\"T_389f6_row2_col3\" class=\"data row2 col3\" >57.4</td>\n",
              "      <td id=\"T_389f6_row2_col4\" class=\"data row2 col4\" >45.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row3_col0\" class=\"data row3 col0\" >No Time Series</td>\n",
              "      <td id=\"T_389f6_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_389f6_row3_col2\" class=\"data row3 col2\" >73.05</td>\n",
              "      <td id=\"T_389f6_row3_col3\" class=\"data row3 col3\" >25.81</td>\n",
              "      <td id=\"T_389f6_row3_col4\" class=\"data row3 col4\" >0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row4_col0\" class=\"data row4 col0\" >No Time Series</td>\n",
              "      <td id=\"T_389f6_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_389f6_row4_col2\" class=\"data row4 col2\" >71.14</td>\n",
              "      <td id=\"T_389f6_row4_col3\" class=\"data row4 col3\" >24.12</td>\n",
              "      <td id=\"T_389f6_row4_col4\" class=\"data row4 col4\" >0.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row5_col0\" class=\"data row5 col0\" >No Time Series</td>\n",
              "      <td id=\"T_389f6_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_389f6_row5_col2\" class=\"data row5 col2\" >73.58</td>\n",
              "      <td id=\"T_389f6_row5_col3\" class=\"data row5 col3\" >27.04</td>\n",
              "      <td id=\"T_389f6_row5_col4\" class=\"data row5 col4\" >0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row6_col0\" class=\"data row6 col0\" >Proposed</td>\n",
              "      <td id=\"T_389f6_row6_col1\" class=\"data row6 col1\" >concat</td>\n",
              "      <td id=\"T_389f6_row6_col2\" class=\"data row6 col2\" >87.43</td>\n",
              "      <td id=\"T_389f6_row6_col3\" class=\"data row6 col3\" >56.65</td>\n",
              "      <td id=\"T_389f6_row6_col4\" class=\"data row6 col4\" >45.17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row7_col0\" class=\"data row7 col0\" >Proposed</td>\n",
              "      <td id=\"T_389f6_row7_col1\" class=\"data row7 col1\" >fasttext</td>\n",
              "      <td id=\"T_389f6_row7_col2\" class=\"data row7 col2\" >87.15</td>\n",
              "      <td id=\"T_389f6_row7_col3\" class=\"data row7 col3\" >56.06</td>\n",
              "      <td id=\"T_389f6_row7_col4\" class=\"data row7 col4\" >44.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row8_col0\" class=\"data row8 col0\" >Proposed</td>\n",
              "      <td id=\"T_389f6_row8_col1\" class=\"data row8 col1\" >word2vec</td>\n",
              "      <td id=\"T_389f6_row8_col2\" class=\"data row8 col2\" >87.46</td>\n",
              "      <td id=\"T_389f6_row8_col3\" class=\"data row8 col3\" >56.89</td>\n",
              "      <td id=\"T_389f6_row8_col4\" class=\"data row8 col4\" >45.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_389f6_row9_col0\" class=\"data row9 col0\" >Time Series</td>\n",
              "      <td id=\"T_389f6_row9_col1\" class=\"data row9 col1\" >-</td>\n",
              "      <td id=\"T_389f6_row9_col2\" class=\"data row9 col2\" >87.77</td>\n",
              "      <td id=\"T_389f6_row9_col3\" class=\"data row9 col3\" >55.62</td>\n",
              "      <td id=\"T_389f6_row9_col4\" class=\"data row9 col4\" >42.94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >3 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_63882_row0_col2, #T_63882_row0_col4, #T_63882_row8_col3 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_63882\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_63882_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_63882_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_63882_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_63882_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_63882_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_63882_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_63882_row0_col2\" class=\"data row0 col2\" >70.1</td>\n",
              "      <td id=\"T_63882_row0_col3\" class=\"data row0 col3\" >64.05</td>\n",
              "      <td id=\"T_63882_row0_col4\" class=\"data row0 col4\" >56.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_63882_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_63882_row1_col2\" class=\"data row1 col2\" >69.83</td>\n",
              "      <td id=\"T_63882_row1_col3\" class=\"data row1 col3\" >63.77</td>\n",
              "      <td id=\"T_63882_row1_col4\" class=\"data row1 col4\" >55.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_63882_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_63882_row2_col2\" class=\"data row2 col2\" >69.93</td>\n",
              "      <td id=\"T_63882_row2_col3\" class=\"data row2 col3\" >63.84</td>\n",
              "      <td id=\"T_63882_row2_col4\" class=\"data row2 col4\" >54.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row3_col0\" class=\"data row3 col0\" >No Time Series</td>\n",
              "      <td id=\"T_63882_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_63882_row3_col2\" class=\"data row3 col2\" >62.45</td>\n",
              "      <td id=\"T_63882_row3_col3\" class=\"data row3 col3\" >53.94</td>\n",
              "      <td id=\"T_63882_row3_col4\" class=\"data row3 col4\" >39.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row4_col0\" class=\"data row4 col0\" >No Time Series</td>\n",
              "      <td id=\"T_63882_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_63882_row4_col2\" class=\"data row4 col2\" >61.75</td>\n",
              "      <td id=\"T_63882_row4_col3\" class=\"data row4 col3\" >52.73</td>\n",
              "      <td id=\"T_63882_row4_col4\" class=\"data row4 col4\" >38.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row5_col0\" class=\"data row5 col0\" >No Time Series</td>\n",
              "      <td id=\"T_63882_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_63882_row5_col2\" class=\"data row5 col2\" >63.19</td>\n",
              "      <td id=\"T_63882_row5_col3\" class=\"data row5 col3\" >54.57</td>\n",
              "      <td id=\"T_63882_row5_col4\" class=\"data row5 col4\" >45.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row6_col0\" class=\"data row6 col0\" >Proposed</td>\n",
              "      <td id=\"T_63882_row6_col1\" class=\"data row6 col1\" >concat</td>\n",
              "      <td id=\"T_63882_row6_col2\" class=\"data row6 col2\" >70.03</td>\n",
              "      <td id=\"T_63882_row6_col3\" class=\"data row6 col3\" >63.95</td>\n",
              "      <td id=\"T_63882_row6_col4\" class=\"data row6 col4\" >55.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row7_col0\" class=\"data row7 col0\" >Proposed</td>\n",
              "      <td id=\"T_63882_row7_col1\" class=\"data row7 col1\" >fasttext</td>\n",
              "      <td id=\"T_63882_row7_col2\" class=\"data row7 col2\" >69.63</td>\n",
              "      <td id=\"T_63882_row7_col3\" class=\"data row7 col3\" >63.7</td>\n",
              "      <td id=\"T_63882_row7_col4\" class=\"data row7 col4\" >54.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row8_col0\" class=\"data row8 col0\" >Proposed</td>\n",
              "      <td id=\"T_63882_row8_col1\" class=\"data row8 col1\" >word2vec</td>\n",
              "      <td id=\"T_63882_row8_col2\" class=\"data row8 col2\" >70.06</td>\n",
              "      <td id=\"T_63882_row8_col3\" class=\"data row8 col3\" >64.23</td>\n",
              "      <td id=\"T_63882_row8_col4\" class=\"data row8 col4\" >55.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_63882_row9_col0\" class=\"data row9 col0\" >Time Series</td>\n",
              "      <td id=\"T_63882_row9_col1\" class=\"data row9 col1\" >-</td>\n",
              "      <td id=\"T_63882_row9_col2\" class=\"data row9 col2\" >69.57</td>\n",
              "      <td id=\"T_63882_row9_col3\" class=\"data row9 col3\" >64.04</td>\n",
              "      <td id=\"T_63882_row9_col4\" class=\"data row9 col4\" >55.29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >7 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_f1a31_row9_col2, #T_f1a31_row9_col3, #T_f1a31_row9_col4 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_f1a31\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_f1a31_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_f1a31_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_f1a31_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_f1a31_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_f1a31_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row0_col0\" class=\"data row0 col0\" >No Convolution</td>\n",
              "      <td id=\"T_f1a31_row0_col1\" class=\"data row0 col1\" >concat</td>\n",
              "      <td id=\"T_f1a31_row0_col2\" class=\"data row0 col2\" >71.12</td>\n",
              "      <td id=\"T_f1a31_row0_col3\" class=\"data row0 col3\" >19.29</td>\n",
              "      <td id=\"T_f1a31_row0_col4\" class=\"data row0 col4\" >2.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row1_col0\" class=\"data row1 col0\" >No Convolution</td>\n",
              "      <td id=\"T_f1a31_row1_col1\" class=\"data row1 col1\" >fasttext</td>\n",
              "      <td id=\"T_f1a31_row1_col2\" class=\"data row1 col2\" >72.14</td>\n",
              "      <td id=\"T_f1a31_row1_col3\" class=\"data row1 col3\" >20.15</td>\n",
              "      <td id=\"T_f1a31_row1_col4\" class=\"data row1 col4\" >3.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row2_col0\" class=\"data row2 col0\" >No Convolution</td>\n",
              "      <td id=\"T_f1a31_row2_col1\" class=\"data row2 col1\" >word2vec</td>\n",
              "      <td id=\"T_f1a31_row2_col2\" class=\"data row2 col2\" >72.48</td>\n",
              "      <td id=\"T_f1a31_row2_col3\" class=\"data row2 col3\" >20.94</td>\n",
              "      <td id=\"T_f1a31_row2_col4\" class=\"data row2 col4\" >2.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row3_col0\" class=\"data row3 col0\" >No Time Series</td>\n",
              "      <td id=\"T_f1a31_row3_col1\" class=\"data row3 col1\" >concat</td>\n",
              "      <td id=\"T_f1a31_row3_col2\" class=\"data row3 col2\" >60.64</td>\n",
              "      <td id=\"T_f1a31_row3_col3\" class=\"data row3 col3\" >10.85</td>\n",
              "      <td id=\"T_f1a31_row3_col4\" class=\"data row3 col4\" >0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row4_col0\" class=\"data row4 col0\" >No Time Series</td>\n",
              "      <td id=\"T_f1a31_row4_col1\" class=\"data row4 col1\" >fasttext</td>\n",
              "      <td id=\"T_f1a31_row4_col2\" class=\"data row4 col2\" >62.21</td>\n",
              "      <td id=\"T_f1a31_row4_col3\" class=\"data row4 col3\" >11.73</td>\n",
              "      <td id=\"T_f1a31_row4_col4\" class=\"data row4 col4\" >0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row5_col0\" class=\"data row5 col0\" >No Time Series</td>\n",
              "      <td id=\"T_f1a31_row5_col1\" class=\"data row5 col1\" >word2vec</td>\n",
              "      <td id=\"T_f1a31_row5_col2\" class=\"data row5 col2\" >63.71</td>\n",
              "      <td id=\"T_f1a31_row5_col3\" class=\"data row5 col3\" >12.4</td>\n",
              "      <td id=\"T_f1a31_row5_col4\" class=\"data row5 col4\" >0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row6_col0\" class=\"data row6 col0\" >Proposed</td>\n",
              "      <td id=\"T_f1a31_row6_col1\" class=\"data row6 col1\" >concat</td>\n",
              "      <td id=\"T_f1a31_row6_col2\" class=\"data row6 col2\" >71.38</td>\n",
              "      <td id=\"T_f1a31_row6_col3\" class=\"data row6 col3\" >20.7</td>\n",
              "      <td id=\"T_f1a31_row6_col4\" class=\"data row6 col4\" >3.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row7_col0\" class=\"data row7 col0\" >Proposed</td>\n",
              "      <td id=\"T_f1a31_row7_col1\" class=\"data row7 col1\" >fasttext</td>\n",
              "      <td id=\"T_f1a31_row7_col2\" class=\"data row7 col2\" >71.74</td>\n",
              "      <td id=\"T_f1a31_row7_col3\" class=\"data row7 col3\" >20.53</td>\n",
              "      <td id=\"T_f1a31_row7_col4\" class=\"data row7 col4\" >1.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row8_col0\" class=\"data row8 col0\" >Proposed</td>\n",
              "      <td id=\"T_f1a31_row8_col1\" class=\"data row8 col1\" >word2vec</td>\n",
              "      <td id=\"T_f1a31_row8_col2\" class=\"data row8 col2\" >72.14</td>\n",
              "      <td id=\"T_f1a31_row8_col3\" class=\"data row8 col3\" >21.01</td>\n",
              "      <td id=\"T_f1a31_row8_col4\" class=\"data row8 col4\" >1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_f1a31_row9_col0\" class=\"data row9 col0\" >Time Series</td>\n",
              "      <td id=\"T_f1a31_row9_col1\" class=\"data row9 col1\" >-</td>\n",
              "      <td id=\"T_f1a31_row9_col2\" class=\"data row9 col2\" >73.54</td>\n",
              "      <td id=\"T_f1a31_row9_col3\" class=\"data row9 col3\" >21.44</td>\n",
              "      <td id=\"T_f1a31_row9_col4\" class=\"data row9 col4\" >4.06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Experiments"
      ],
      "metadata": {
        "id": "RzOjcgXQyGEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter tuning\n",
        "Section 4.1 from the paper states that the authors independently tuned hyperparameters for all models. The proposed model at the beginning of this section uses the hyperparameter values stated in the paper, however, tuning hyperparameters for our current environment may improve performance and perhaps standard deviation as well.\n",
        "\n",
        "The following hyperparameters are tuned on the validation set only using Word2Vec and In hospital mortality for 1 iteration and 5 epochs:\n",
        "- number of hidden untis (original = 256, best = no change)\n",
        "- convolutional filters (original = [32, 64, 96], best = [64, 96, 128])\n",
        "- learning rate (original = 0.001, best = no change)\n",
        "- dropout rates (original = 0.2, best = 0.5)\n",
        "- regularization parameters (original = 0.01, best = 0.1)\n",
        "\n",
        "Not all hyperparameters were tuned and smaller ranges were used due to time constraints. The tuned model results are also only abvailable for Word2vec and FastText due to usage limits in colab as this was the last model run.\n",
        "\n",
        "The tuned model outperformed the proposed model, except for F1 scores for in-ICU mortality and length of stay > 7 days. However the standard deviation was still high. The results of the model with these hyperparameters are below.\n",
        "\n",
        "Note: did not include ablations as results are not comparable due to differences in paramters, however, doing ablations on this model would be an interesting experiment to compare the effects."
      ],
      "metadata": {
        "id": "hRffoootyS8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize HTML string\n",
        "html_output = \"<table style='border-collapse: collapse; border: 1px solid black;'>\"\n",
        "\n",
        "# Group by Task and apply highlighting, then add to the HTML output\n",
        "for i, (name, group) in enumerate(full_results.groupby(\"Task\")):\n",
        "    group.drop(group.columns[0], axis=1, inplace=True)\n",
        "    group = group[group['Model'].isin(['Proposed', \"Proposed (Tuned)\"])]\n",
        "    group = group[group['Embedding'].isin(['word2vec','fasttext'])]\n",
        "    styled_group = group.style.apply(highlight_max_group, subset=[\"AUC\", \"AUPRC\", \"F1\"])\n",
        "    # format scores back to 2 decimal places and hide index\n",
        "    styled_group = styled_group.format({col: \"{:.4}\" for col in [\"AUC\", \"AUPRC\", \"F1\"]})\n",
        "    styled_group = styled_group.hide(axis=\"index\")\n",
        "    # Add title as task name\n",
        "    html_output += f\"<td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>{name}</td>\"\n",
        "    # Convert styled DataFrame to HTML and add to the output\n",
        "    html_output += f\"<td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'>{styled_group.to_html()}</td>\"\n",
        "    # Display only two tables in a row\n",
        "    if (i + 1) % 2 == 0:\n",
        "        html_output += \"</tr><tr>\"\n",
        "\n",
        "# Close table\n",
        "html_output += \"</table>\"\n",
        "display(HTML(html_output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "zdxRmP1KzHi6",
        "outputId": "a65f1a8a-083d-4503-beb8-4b9c526f584d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style='border-collapse: collapse; border: 1px solid black;'><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-ICU mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_51556_row1_col4, #T_51556_row2_col3, #T_51556_row3_col2 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_51556\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_51556_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_51556_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_51556_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_51556_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_51556_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_51556_row0_col0\" class=\"data row0 col0\" >Proposed</td>\n",
              "      <td id=\"T_51556_row0_col1\" class=\"data row0 col1\" >fasttext</td>\n",
              "      <td id=\"T_51556_row0_col2\" class=\"data row0 col2\" >87.19</td>\n",
              "      <td id=\"T_51556_row0_col3\" class=\"data row0 col3\" >49.7</td>\n",
              "      <td id=\"T_51556_row0_col4\" class=\"data row0 col4\" >39.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_51556_row1_col0\" class=\"data row1 col0\" >Proposed</td>\n",
              "      <td id=\"T_51556_row1_col1\" class=\"data row1 col1\" >word2vec</td>\n",
              "      <td id=\"T_51556_row1_col2\" class=\"data row1 col2\" >87.47</td>\n",
              "      <td id=\"T_51556_row1_col3\" class=\"data row1 col3\" >50.23</td>\n",
              "      <td id=\"T_51556_row1_col4\" class=\"data row1 col4\" >40.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_51556_row2_col0\" class=\"data row2 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_51556_row2_col1\" class=\"data row2 col1\" >fasttext</td>\n",
              "      <td id=\"T_51556_row2_col2\" class=\"data row2 col2\" >88.11</td>\n",
              "      <td id=\"T_51556_row2_col3\" class=\"data row2 col3\" >50.71</td>\n",
              "      <td id=\"T_51556_row2_col4\" class=\"data row2 col4\" >40.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_51556_row3_col0\" class=\"data row3 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_51556_row3_col1\" class=\"data row3 col1\" >word2vec</td>\n",
              "      <td id=\"T_51556_row3_col2\" class=\"data row3 col2\" >88.16</td>\n",
              "      <td id=\"T_51556_row3_col3\" class=\"data row3 col3\" >50.43</td>\n",
              "      <td id=\"T_51556_row3_col4\" class=\"data row3 col4\" >39.98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>In-hospital mortality</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_1cbe7_row3_col2, #T_1cbe7_row3_col3, #T_1cbe7_row3_col4 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_1cbe7\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_1cbe7_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_1cbe7_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_1cbe7_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_1cbe7_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_1cbe7_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_1cbe7_row0_col0\" class=\"data row0 col0\" >Proposed</td>\n",
              "      <td id=\"T_1cbe7_row0_col1\" class=\"data row0 col1\" >fasttext</td>\n",
              "      <td id=\"T_1cbe7_row0_col2\" class=\"data row0 col2\" >87.15</td>\n",
              "      <td id=\"T_1cbe7_row0_col3\" class=\"data row0 col3\" >56.06</td>\n",
              "      <td id=\"T_1cbe7_row0_col4\" class=\"data row0 col4\" >44.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1cbe7_row1_col0\" class=\"data row1 col0\" >Proposed</td>\n",
              "      <td id=\"T_1cbe7_row1_col1\" class=\"data row1 col1\" >word2vec</td>\n",
              "      <td id=\"T_1cbe7_row1_col2\" class=\"data row1 col2\" >87.46</td>\n",
              "      <td id=\"T_1cbe7_row1_col3\" class=\"data row1 col3\" >56.89</td>\n",
              "      <td id=\"T_1cbe7_row1_col4\" class=\"data row1 col4\" >45.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1cbe7_row2_col0\" class=\"data row2 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_1cbe7_row2_col1\" class=\"data row2 col1\" >fasttext</td>\n",
              "      <td id=\"T_1cbe7_row2_col2\" class=\"data row2 col2\" >87.72</td>\n",
              "      <td id=\"T_1cbe7_row2_col3\" class=\"data row2 col3\" >56.37</td>\n",
              "      <td id=\"T_1cbe7_row2_col4\" class=\"data row2 col4\" >44.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_1cbe7_row3_col0\" class=\"data row3 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_1cbe7_row3_col1\" class=\"data row3 col1\" >word2vec</td>\n",
              "      <td id=\"T_1cbe7_row3_col2\" class=\"data row3 col2\" >88.13</td>\n",
              "      <td id=\"T_1cbe7_row3_col3\" class=\"data row3 col3\" >57.36</td>\n",
              "      <td id=\"T_1cbe7_row3_col4\" class=\"data row3 col4\" >46.01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >3 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_9b213_row3_col2, #T_9b213_row3_col3, #T_9b213_row3_col4 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_9b213\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_9b213_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_9b213_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_9b213_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_9b213_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_9b213_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_9b213_row0_col0\" class=\"data row0 col0\" >Proposed</td>\n",
              "      <td id=\"T_9b213_row0_col1\" class=\"data row0 col1\" >fasttext</td>\n",
              "      <td id=\"T_9b213_row0_col2\" class=\"data row0 col2\" >69.63</td>\n",
              "      <td id=\"T_9b213_row0_col3\" class=\"data row0 col3\" >63.7</td>\n",
              "      <td id=\"T_9b213_row0_col4\" class=\"data row0 col4\" >54.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_9b213_row1_col0\" class=\"data row1 col0\" >Proposed</td>\n",
              "      <td id=\"T_9b213_row1_col1\" class=\"data row1 col1\" >word2vec</td>\n",
              "      <td id=\"T_9b213_row1_col2\" class=\"data row1 col2\" >70.06</td>\n",
              "      <td id=\"T_9b213_row1_col3\" class=\"data row1 col3\" >64.23</td>\n",
              "      <td id=\"T_9b213_row1_col4\" class=\"data row1 col4\" >55.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_9b213_row2_col0\" class=\"data row2 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_9b213_row2_col1\" class=\"data row2 col1\" >fasttext</td>\n",
              "      <td id=\"T_9b213_row2_col2\" class=\"data row2 col2\" >70.03</td>\n",
              "      <td id=\"T_9b213_row2_col3\" class=\"data row2 col3\" >64.35</td>\n",
              "      <td id=\"T_9b213_row2_col4\" class=\"data row2 col4\" >55.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_9b213_row3_col0\" class=\"data row3 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_9b213_row3_col1\" class=\"data row3 col1\" >word2vec</td>\n",
              "      <td id=\"T_9b213_row3_col2\" class=\"data row3 col2\" >70.62</td>\n",
              "      <td id=\"T_9b213_row3_col3\" class=\"data row3 col3\" >64.83</td>\n",
              "      <td id=\"T_9b213_row3_col4\" class=\"data row3 col4\" >56.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td><td colspan='2' style='border: 1px solid black; text-align: center; padding: 5px; font-weight: bold;'>LOS >7 days</td><td style='border: 1px solid black; text-align: center; padding: 8px;line-height: 20px;'><style type=\"text/css\">\n",
              "#T_d7d57_row0_col4, #T_d7d57_row3_col2, #T_d7d57_row3_col3 {\n",
              "  background-color: orange;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_d7d57\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_d7d57_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_d7d57_level0_col1\" class=\"col_heading level0 col1\" >Embedding</th>\n",
              "      <th id=\"T_d7d57_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_d7d57_level0_col3\" class=\"col_heading level0 col3\" >AUPRC</th>\n",
              "      <th id=\"T_d7d57_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_d7d57_row0_col0\" class=\"data row0 col0\" >Proposed</td>\n",
              "      <td id=\"T_d7d57_row0_col1\" class=\"data row0 col1\" >fasttext</td>\n",
              "      <td id=\"T_d7d57_row0_col2\" class=\"data row0 col2\" >71.74</td>\n",
              "      <td id=\"T_d7d57_row0_col3\" class=\"data row0 col3\" >20.53</td>\n",
              "      <td id=\"T_d7d57_row0_col4\" class=\"data row0 col4\" >1.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_d7d57_row1_col0\" class=\"data row1 col0\" >Proposed</td>\n",
              "      <td id=\"T_d7d57_row1_col1\" class=\"data row1 col1\" >word2vec</td>\n",
              "      <td id=\"T_d7d57_row1_col2\" class=\"data row1 col2\" >72.14</td>\n",
              "      <td id=\"T_d7d57_row1_col3\" class=\"data row1 col3\" >21.01</td>\n",
              "      <td id=\"T_d7d57_row1_col4\" class=\"data row1 col4\" >1.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_d7d57_row2_col0\" class=\"data row2 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_d7d57_row2_col1\" class=\"data row2 col1\" >fasttext</td>\n",
              "      <td id=\"T_d7d57_row2_col2\" class=\"data row2 col2\" >72.73</td>\n",
              "      <td id=\"T_d7d57_row2_col3\" class=\"data row2 col3\" >21.86</td>\n",
              "      <td id=\"T_d7d57_row2_col4\" class=\"data row2 col4\" >0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_d7d57_row3_col0\" class=\"data row3 col0\" >Proposed (Tuned)</td>\n",
              "      <td id=\"T_d7d57_row3_col1\" class=\"data row3 col1\" >word2vec</td>\n",
              "      <td id=\"T_d7d57_row3_col2\" class=\"data row3 col2\" >73.13</td>\n",
              "      <td id=\"T_d7d57_row3_col3\" class=\"data row3 col3\" >22.49</td>\n",
              "      <td id=\"T_d7d57_row3_col4\" class=\"data row3 col4\" >0.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</td></tr><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_std[(results_std['Model'] == 'Proposed (Tuned)')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "PjOTe0GyzIKu",
        "outputId": "a3a32d2c-099d-431a-d0b9-7d285010b772"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Task             Model Embedding  AUC_std  AUPRC_std  \\\n",
              "9        In-ICU mortality  Proposed (Tuned)  fasttext     0.30       0.88   \n",
              "10       In-ICU mortality  Proposed (Tuned)  word2vec     0.41       0.89   \n",
              "21  In-hospital mortality  Proposed (Tuned)  fasttext     0.34       0.89   \n",
              "22  In-hospital mortality  Proposed (Tuned)  word2vec     0.37       0.84   \n",
              "33            LOS >3 days  Proposed (Tuned)  fasttext     0.46       0.45   \n",
              "34            LOS >3 days  Proposed (Tuned)  word2vec     0.29       0.28   \n",
              "45            LOS >7 days  Proposed (Tuned)  fasttext     0.91       0.90   \n",
              "46            LOS >7 days  Proposed (Tuned)  word2vec     0.91       1.02   \n",
              "\n",
              "    F1_std  \n",
              "9     5.12  \n",
              "10    6.15  \n",
              "21    1.91  \n",
              "22    1.68  \n",
              "33    2.31  \n",
              "34    2.68  \n",
              "45    0.87  \n",
              "46    0.54  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87b646fc-685b-4991-b173-30ec38039b24\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Task</th>\n",
              "      <th>Model</th>\n",
              "      <th>Embedding</th>\n",
              "      <th>AUC_std</th>\n",
              "      <th>AUPRC_std</th>\n",
              "      <th>F1_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.88</td>\n",
              "      <td>5.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>In-ICU mortality</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.89</td>\n",
              "      <td>6.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.89</td>\n",
              "      <td>1.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>In-hospital mortality</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.84</td>\n",
              "      <td>1.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.45</td>\n",
              "      <td>2.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>LOS &gt;3 days</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>fasttext</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>LOS &gt;7 days</td>\n",
              "      <td>Proposed (Tuned)</td>\n",
              "      <td>word2vec</td>\n",
              "      <td>0.91</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0.54</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b646fc-685b-4991-b173-30ec38039b24')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-87b646fc-685b-4991-b173-30ec38039b24 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-87b646fc-685b-4991-b173-30ec38039b24');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9fb228f-f4f2-4555-afcc-fa033fa3c6bb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9fb228f-f4f2-4555-afcc-fa033fa3c6bb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9fb228f-f4f2-4555-afcc-fa033fa3c6bb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"results_std[(results_std['Model'] == 'Proposed (Tuned)')]\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"In-hospital mortality\",\n          \"LOS >7 days\",\n          \"In-ICU mortality\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Proposed (Tuned)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embedding\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"word2vec\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUC_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2598041845038572,\n        \"min\": 0.29,\n        \"max\": 0.91,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AUPRC_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.25848114051125665,\n        \"min\": 0.27999999999999997,\n        \"max\": 1.02,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.88\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1_std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9847975787398142,\n        \"min\": 0.54,\n        \"max\": 6.15,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0f_jN20zH-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discussion\n",
        "\n",
        "This section provides an assessment of the work done and recommendations to the authors.\n",
        "\n",
        "## Assessment\n",
        "\n",
        "The paper was partially reproducible. Only the experiment AUC scores were close to the reported scores. Ablation studies also showed that convolution did not improve results for most tasks as hypothesized in the paper, but improvement from the multimodal effect was confirmed for most tasks. **Due to the high standard deviation in the resukts, it is possible for someone to get the same results as the authors.**\n",
        "\n",
        "### Reproduction efforts\n",
        "* Used the author's code, with modifications for efficiency and fixes.\n",
        "* Used the parameters specified from the paper and the code where unspecified.\n",
        "* Split the data as the paper specified and created the cohort as described as well.\n",
        "\n",
        "### Factors that made the paper irreproducible\n",
        "* Differences in package versions as the requirements file was not provided. The code is 4 years old and some library methods were depricated.\n",
        "* The final cohort was 22,203 patients compared to the reported 21,080. This difference may be due to changes in the MIMIC datasets. The paper was also missing a full/exact description of how clinical notes were preprocessed.\n",
        "* Possible changes to word embeddings. Most noticeably: from the papers code, FastText seemed to have more words than Word2Vec. However, the experiement revealed that they has the same words, which resulted in the code failing during training.\n",
        "* The paper was missing some parameters and hyperparameters like batch size, patient matrix column dimension (size parameter for the get_subvector_data function), kernel size, and early stopping number. (with more time, thorough hyperparameter tuning may have been helpful)\n",
        "* Despite setting seeds, the standard deviations of the model results were high, expecially on GPU vs CPU. Rerunning the model could give slightly different results even when averaging.\n",
        "\n",
        "### Communication with original authors\n",
        "I reached out to one of the original authors, Batuhan Bardak. I shared my results, explained that the packages may be the biggest difference and asked for a requirements file. They could not provide one as the code is old, but they were kind enough to offer other possible reasons for the discrepancies quoted below:\n",
        "\n",
        "\"I believe this issue could be due to the following reasons:\n",
        "\n",
        "- changes in the MIMIC-III dataset (in terms of the number of samples or attributes)\n",
        "- differences in library version (as you mentioned)\n",
        "- differences in the word embeddings\n",
        "- General randomness (library, hardware, model, weight initialization etc.)\n",
        "\"\n",
        "\n",
        "## What was easy\n",
        "- The author's code in their GitHub repository made reproducing the experiments easier. It offered a very good starting point and had all the experiements in the paper. The first half of the author's code was generally easy to run. Specifically:\n",
        "\n",
        "    - The original time series data processing code (01-Extract-Timeseries-Features.ipynb) ran well with no errors except for a memory error when reading the data. These memory errors were resolved by modifying the code to run within the memory constraints by only reading the admissions file once instead of twice as the authors did. However, when running with 24 GB RAM, no modifications are needed.\n",
        "    - The code to process the clinical notes up to the application of NER ran well with no errors (02-Select-SubClinicalNotes.ipynb, 03-Preprocess-Clinical-Notes.ipynb, 04-Apply-med7-on-Clinical-Notes.ipynb).\n",
        "\n",
        "- The main idea and method the paper used were very well explained and did not require advanced knowledge to follow.\n",
        "- Not having to run the MIMIC-Extract code as the preprocessed data was saved in Google Cloud Platform. From the GitHub page execution \" Will probably take 5-10 hours. Will require a good machine with at least 50GB RAM.\"\n",
        "\n",
        "\n",
        "## What was difficult\n",
        "- The major difficulty was from the lack of a requirements file. A lot of libraries and methods were deprecated or methods were moved to different modules so the code needed to be changed (particularly the model code). This may not prove as difficult for someone familiar with the Keras.\n",
        "- The data processing code took 3+ days to run on the full dataset. The med7 application particularly took the longest (about 15 hours). With Google Colabs 12 hour limit, modifications needed to be made to run it in chunks.\n",
        "- There were extra preprocessing steps in the code that were commented out and seemed unused. I would have liked to apply the extra steps to see if the results changed, but unfortunately that would take too long as mentioned in the previous point.\n",
        "- The script to represent medical entities with word embeddings (05-Represent-Entities-With-Different-Embeddings.ipynb) produced errors when running the model and needed to be debugged. This required some time and effort to fix for all 3 embeddings. (Note: the final cell of the script also had a reference error, but this was an easy fix).\n",
        "- The FastText model was missing from the GitHub link provided in the author's GitHub ReadMe page. After getting no response from the model creators, I noticed that someone else had raised this as an issue on the papers author's GitHub page and they provided a link to the embeddings.\n",
        "- The volatility in the model results was not expected, rerunning the model produced varying results even after setting seed. After researching, it became apparent that performing hyperparameter tuning (as the authors did) may prove helpful. There were many parameters to tune which took time to run, and I was only able to get the results for Word2Vec and FastText within the limited time and colab runtime limits.\n",
        "- If using Colab, it also takes some time to upload `all_hourly_data.csv` to Google Drive (I let it upload overnight).\n",
        "- I also attempted to use transformers instead of convolution but the model was very slow, even on GPU and the runtime was disconnected before completing the 7th iteration of Word2Vec. The code is commented out and the output displayed in `all_models.ipynb` file for reference.\n",
        "\n",
        "\n",
        "## Recommendations to original authors\n",
        "\n",
        "Firstly, creating a GitHub page for this paper was very helpful and valuable. The paper was also generally well-written with a lot of detail. However, here are a few recommendations:\n",
        "\n",
        "- To provide a requirements.txt file to ensure that the code can be run easily and ensure reproducibility.\n",
        "- Specify all parameters in the paper including batch size, seeds, kernel size.\n",
        "\n"
      ],
      "metadata": {
        "id": "knq_PVUcOKBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking that the whole notebook does not exceed 8 mins (not a hard rule but needs to run fast))\n",
        "print(\"Total running time = {:.2f} minutes\".format((time.time() - _START_RUNTIME)/60))"
      ],
      "metadata": {
        "id": "QoH1pXMmGscu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a26672bf-11d8-41e3-c3a3-1af7f25f1ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total running time = 7.68 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "[1] Johnson, A., Pollard, T., Shen, L. et al. MIMIC-III, a freely accessible critical care database. Sci Data 3, 160035 (2016). https://doi.org/10.1038/sdata.2016.35\n",
        "\n",
        "[2] Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Michael C. Hughes, Tristan Naumann, and Marzyeh Ghassemi. MIMIC-Extract: A Data Extraction, Preprocessing, and Representation Pipeline for MIMIC-III. arXiv:1907.08322. https://arxiv.org/pdf/1907.08322.pdf\n",
        "\n",
        "[3]  Kormilitzin A, Vaci N, Liu Q, Nevado-Holgado A. Med7: a transferable clinical natural language processing model for electronic health records. 2020 (arXiv preprint), arXiv:2003.01271. https://arxiv.org/pdf/2003.01271\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMI2chl9omn"
      }
    }
  ]
}